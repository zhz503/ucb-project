{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project （part 2）\n",
    "Team leader: Zhaoliang Zheng\n",
    "\n",
    "Team member: Anqi Shen, Enbo Yu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzl\\data\\final project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ROOTDIR = os.path.abspath(os.path.dirname('__file__'))\n",
    "print(ROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Load dataset and check it\n",
    "df = pd.read_csv(os.path.join(ROOTDIR, 'fake_or_real_news.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a binarize function and binrize the label\n",
    "def binarize(word):\n",
    "    if word== 'REAL':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df.label= df.label.apply(binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in this step, I'm gonna drop the first column which is meaningless here\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: DATA PROCESSING:TOKENIZE & CLEAN THE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import models\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load raw title and text dataset into different varibles\n",
    "texts = df.text.values\n",
    "titles = df.title.values\n",
    "#simply tokenize the text and title\n",
    "tokenized_text = [nltk.word_tokenize(text) for text in texts]\n",
    "tokenized_title = [nltk.word_tokenize(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "def clean_advance(tokenized_list, sw):\n",
    "    new_list = []\n",
    "    for doc in tokenized_list:\n",
    "        new_list.append([token.lower() for token in doc if token.lower() not in sw\n",
    "                        and token.lower() != \"“\" and token.lower() != \"”\"\n",
    "                        and token.lower() != \"‘\" and token.lower() != \"’\"\n",
    "                        and token.lower() != \"``\" and token.lower() != \"''\"\n",
    "                        and token.lower() != \"—\"  and token.lower() != \"–\"\n",
    "                        and token.lower() !=\",\" and token.lower() != \".\"\n",
    "                        and token.lower() != \":\" and token.lower() != \"?\"\n",
    "                        and token.lower() != \"(\" and token.lower() != \")\"\n",
    "                        and token.lower() != \"'s\" and token.lower() != \"n't\"\n",
    "                        and token.lower() != \"'d\" and token.lower() != \"'ve\"\n",
    "                        and token.lower() != \"!\" and token.lower() != \"'\"\n",
    "                        and token.lower() != \"&\" and token.lower() != \"*\"\n",
    "                        and token.lower() != \"...\" and token.lower() != \"…\" \n",
    "                        and token.lower() != \"#\" and token.lower() != \"-\"\n",
    "                        and token.lower() != \"[\" and token.lower() != \"]\" \n",
    "                        and token.lower() != \"%\" and token.lower() !=\"|\" \n",
    "                        and token.lower() != \";\" ])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuations and stopwords,lower-case and other useless mark from tokenized title and text\n",
    "cleaned_title = clean_advance(tokenized_title, sw)\n",
    "cleaned_text = clean_advance(tokenized_text, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.      trump  freq:   21906\n",
      " 2.       said  freq:   21162\n",
      " 3.    clinton  freq:   17237\n",
      " 4.      would  freq:   12928\n",
      " 5.     people  freq:   11598\n",
      " 6.        one  freq:   11295\n",
      " 7.        new  freq:    9263\n",
      " 8.      state  freq:    8744\n",
      " 9.  president  freq:    8509\n",
      "10.       also  freq:    8206\n",
      "11.      obama  freq:    8121\n",
      "12.   campaign  freq:    7642\n",
      "13.         us  freq:    7511\n",
      "14.    hillary  freq:    7127\n",
      "15.       like  freq:    7038\n",
      "16.      could  freq:    6705\n",
      "17.       time  freq:    6432\n",
      "18.       even  freq:    6424\n",
      "19.     states  freq:    6142\n",
      "20.       many  freq:    5847\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "token_counter = Counter(token.lower() for sentence in cleaned_text for token in sentence)\n",
    "top20 = token_counter.most_common()[:20]\n",
    "for i, t in enumerate(top20):\n",
    "    print('{:>2}.{:>11}  freq: {:>7}'.format(i+1, t[0], t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1way：Extend title with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "c_extend=copy.deepcopy(cleaned_title)\n",
    "for i in range(texts.shape[0]):\n",
    "   c_extend[i].extend(cleaned_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(c_extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2way：Put title with text into two varibles and weight them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_title=copy.deepcopy(cleaned_title)\n",
    "c_text=copy.deepcopy(cleaned_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smell', 'hillary', 'fear']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Feature extration & vecterize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method1: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "#x_extend = vec.fit_transform(c_extend)\n",
    "#x_title = vec.fit_transform(c_title)\n",
    "#x_text = vec.fit_transform(c_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_str = []\n",
    "for words in c_extend:\n",
    "    str = ''\n",
    "    for i in words:\n",
    "        str += i\n",
    "        str += ' '\n",
    "    vec_str.append(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer.fit(vec_str)\n",
    "tfidf_extend = vectorizer.transform(vec_str)\n",
    "tfidf_m=tfidf_extend.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 67918) (6335, 67918)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_m.shape,tfidf_extend.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "disadvantages:\n",
    "- vector sizes become huge, equal to vocabulary size\n",
    "    - sparsity\n",
    "    - curse of dimensionality\n",
    "    - computationally expensive\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n",
    "\n",
    "Perhaps the easiest naive Bayes classifier to understand is Gaussian naive Bayes. \n",
    "\n",
    "Of course, the final classification will only be as good as the model assumptions that lead to it, which is why Gaussian naive Bayes often does not produce very good results. Still, in many cases—especially as the number of features becomes large—this assumption is not detrimental enough to prevent Gaussian naive Bayes from being a useful method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "The Gaussian assumption just described is by no means the only simple assumption that could be used to specify the generative distribution for each label. Another useful example is multinomial naive Bayes, where the features are assumed to be generated from a simple multinomial distribution. The multinomial distribution describes the probability of observing counts among a number of categories, and thus multinomial naive Bayes is most appropriate for features that represent counts or count rates.\n",
    "\n",
    "The idea is precisely the same as before, except that instead of modeling the data distribution with the best-fit Gaussian, we model the data distribuiton with a best-fit multinomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "modelNB = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Naive Bayes\n",
    "- Because naive Bayesian classifiers make such stringent assumptions about data, they will generally not perform as well as a more complicated model. That said, they have several advantages:\n",
    "    - They are extremely fast for both training and prediction\n",
    "    - They provide straightforward probabilistic prediction\n",
    "    - They are often very easily interpretable\n",
    "    - They have very few (if any) tunable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "# Create a dictionary from list of documents\n",
    "dictionary = corpora.Dictionary(c_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in c_text]\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example review featurized with TF-IDF scores : \n",
      "[('hillary', 0.078), ('political', 0.021), ('bernie', 0.044), ('supporters', 0.072), ('tried', 0.044), ('clinton', 0.295), ('campaign', 0.137), ('clintons', 0.062), ('eluded', 0.126), ('fire', 0.101), ('glimpse', 0.092), ('iowa', 0.34), ('three', 0.029), ('even', 0.03), ('news', 0.042), ('lead', 0.037), ('bill', 0.101), ('need', 0.053), ('--', 0.074), ('sanders', 0.043), ('ever', 0.033), ('hope', 0.041), ('interview', 0.04), ('near', 0.046), ('woman', 0.087), ('policy', 0.03), ('saturday', 0.099), ('right', 0.023), ('lays', 0.095), ('added', 0.036), ('gold', 0.07), ('turn', 0.041), ('plan', 0.039), ('wife', 0.157), ('voters', 0.03), ('help', 0.03), ('two', 0.017), ('days', 0.088), ('president', 0.031), ('book', 0.099), ('old', 0.045), ('one', 0.019), ('cnn', 0.04), ('latest', 0.044), ('run', 0.035), ('show', 0.032), ('work', 0.027), ('years', 0.037), ('long', 0.027), ('democrats', 0.032), ('deliver', 0.066), ('different', 0.035), ('instead', 0.035), ('poll', 0.091), ('think', 0.022), ('changed', 0.102), ('job', 0.04), ('months', 0.033), ('holding', 0.052), ('former', 0.025), ('young', 0.043), ('state', 0.016), ('grasp', 0.092), ('test', 0.058), ('someone', 0.077), ('31', 0.062), ('least', 0.029), ('shows', 0.042), ('people', 0.012), ('network', 0.05), ('top', 0.032), ('said', 0.057), ('role', 0.041), ('rallies', 0.066), ('could', 0.015), ('yes', 0.05), ('inside', 0.05), ('since', 0.022), ('told', 0.043), ('best', 0.033), ('speaker', 0.053), ('say', 0.021), ('way', 0.02), ('slew', 0.109), ('put', 0.028), ('far', 0.027), ('general', 0.032), ('vermont', 0.06), ('loss', 0.055), ('shake', 0.086), ('determine', 0.063), ('considered', 0.05), ('closing', 0.069), ('easily', 0.057), ('entire', 0.043), ('room', 0.052), ('better', 0.031), ('behind', 0.034), ('last', 0.018), ('finally', 0.048), ('night', 0.072), ('sign', 0.046), ('events', 0.049), ('standard', 0.059), ('candidate', 0.054), ('backers', 0.075), ('men', 0.042), ('knows', 0.048), ('chelsea', 0.177), ('leaving', 0.055), ('whether', 0.028), ('stage', 0.049), ('morning', 0.044), ('bring', 0.043), ('quit', 0.079), ('gave', 0.044), ('low', 0.053), ('also', 0.011), ('label', 0.091), ('center', 0.039), ('school', 0.047), ('caucuses', 0.128), ('missouri', 0.074), ('bloomberg', 0.073), ('crowd', 0.161), ('almost', 0.036), ('statement', 0.037), ('high', 0.036), ('energy', 0.104), ('voice', 0.117), ('slog', 0.11), ('known', 0.038), ('thank', 0.133), ('audience', 0.058), ('des', 0.083), ('moines', 0.087), ('register', 0.08), ('monday', 0.042), ('focuses', 0.084), ('hours', 0.043), ('anticipation', 0.106), ('rival', 0.118), ('others', 0.033), ('held', 0.041), ('ago', 0.033), ('positive', 0.056), ('organization', 0.048), ('eight', 0.05), ('hour', 0.06), ('certain', 0.048), ('carried', 0.06), ('signs', 0.058), ('devastating', 0.073), ('aides', 0.063), ('career', 0.06), ('commitment', 0.066), ('bigger', 0.06), ('sen.', 0.039), ('settled', 0.08), ('facing', 0.056), ('struggled', 0.074), ('level', 0.043), ('1992', 0.076), ('acknowledges', 0.095), ('confident', 0.131), ('seemed', 0.103), ('improved', 0.084), ('father', 0.055), ('feeling', 0.127), ('opening', 0.062), ('stood', 0.061), ('indicate', 0.076), ('perhaps', 0.042), ('carrying', 0.066), ('spent', 0.046), ('wary', 0.089), ('enthusiasm', 0.079), ('endorsements', 0.084), ('draw', 0.131), ('waited', 0.086)]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "print('Example review featurized with TF-IDF scores : \\n{}'.format([(dictionary[i[0]], round(i[1],3)) for i in tfidf[corpus[n]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 1389\n",
      "<class 'list'> 1389\n"
     ]
    }
   ],
   "source": [
    "feature_importance = []\n",
    "w_tfidf= []\n",
    "for i in range(texts.shape[0]):\n",
    "    for j in tfidf[corpus[i]]:\n",
    "        if round(j[1],3) > 0.5 and round(j[1],3) < 0.6:\n",
    "             feature_importance.append(dictionary[j[0]])\n",
    "             w_tfidf.append(round(j[1],3))\n",
    "#important_words = list(set(important_words))\n",
    "print(type(feature_importance),len(feature_importance))\n",
    "print(type(w_tfidf),len(w_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature word: fbi ,         TF-IDF scores: 0.59 \n",
      "feature word: ryan ,         TF-IDF scores: 0.566 \n",
      "feature word: va ,         TF-IDF scores: 0.514 \n",
      "feature word: picture ,         TF-IDF scores: 0.511 \n",
      "feature word: sanctions ,         TF-IDF scores: 0.502 \n",
      "feature word: metabiology ,         TF-IDF scores: 0.526 \n",
      "feature word: muscles ,         TF-IDF scores: 0.591 \n",
      "feature word: c ,         TF-IDF scores: 0.56 \n",
      "feature word: hindu ,         TF-IDF scores: 0.521 \n",
      "feature word: weiner ,         TF-IDF scores: 0.503 \n",
      "feature word: hike ,         TF-IDF scores: 0.509 \n",
      "feature word: afghanistan ,         TF-IDF scores: 0.54 \n",
      "feature word: abuse ,         TF-IDF scores: 0.531 \n",
      "feature word: substance ,         TF-IDF scores: 0.592 \n",
      "feature word: crops ,         TF-IDF scores: 0.505 \n",
      "feature word: facebook ,         TF-IDF scores: 0.539 \n",
      "feature word: hispanic ,         TF-IDF scores: 0.528 \n",
      "feature word: hispanics ,         TF-IDF scores: 0.502 \n",
      "feature word: laconia ,         TF-IDF scores: 0.531 \n",
      "feature word: botox ,         TF-IDF scores: 0.516 \n",
      "feature word: skin ,         TF-IDF scores: 0.55 \n",
      "feature word: brown ,         TF-IDF scores: 0.534 \n",
      "feature word: wilson ,         TF-IDF scores: 0.553 \n",
      "feature word: isis ,         TF-IDF scores: 0.567 \n",
      "feature word: cruz ,         TF-IDF scores: 0.541 \n",
      "feature word: johnson ,         TF-IDF scores: 0.592 \n",
      "feature word: alt ,         TF-IDF scores: 0.572 \n",
      "feature word: israel ,         TF-IDF scores: 0.559 \n",
      "feature word: comey ,         TF-IDF scores: 0.551 \n",
      "feature word: mccain ,         TF-IDF scores: 0.546 \n",
      "feature word: cosby ,         TF-IDF scores: 0.57 \n",
      "feature word: podestaemails20 ,         TF-IDF scores: 0.523 \n",
      "feature word: trumped ,         TF-IDF scores: 0.586 \n",
      "feature word: iran ,         TF-IDF scores: 0.518 \n",
      "feature word: saturn ,         TF-IDF scores: 0.522 \n",
      "feature word: switched ,         TF-IDF scores: 0.523 \n",
      "feature word: malley ,         TF-IDF scores: 0.533 \n",
      "feature word: quarter ,         TF-IDF scores: 0.574 \n",
      "feature word: ballistic ,         TF-IDF scores: 0.505 \n",
      "feature word: assange ,         TF-IDF scores: 0.574 \n",
      "feature word: sanders ,         TF-IDF scores: 0.533 \n",
      "feature word: moore ,         TF-IDF scores: 0.527 \n",
      "feature word: culchie ,         TF-IDF scores: 0.544 \n",
      "feature word: sanders ,         TF-IDF scores: 0.521 \n",
      "feature word: 'historic ,         TF-IDF scores: 0.504 \n",
      "feature word: hookem ,         TF-IDF scores: 0.511 \n",
      "feature word: scalia ,         TF-IDF scores: 0.507 \n",
      "feature word: kennedy ,         TF-IDF scores: 0.536 \n",
      "feature word: kasich ,         TF-IDF scores: 0.563 \n",
      "feature word:  ,         TF-IDF scores: 0.593 \n",
      "feature word: implodes ,         TF-IDF scores: 0.561 \n",
      "feature word: israel ,         TF-IDF scores: 0.559 \n",
      "feature word: russia ,         TF-IDF scores: 0.51 \n",
      "feature word: harf ,         TF-IDF scores: 0.501 \n",
      "feature word: waters ,         TF-IDF scores: 0.505 \n",
      "feature word: aleppo ,         TF-IDF scores: 0.504 \n",
      "feature word: paul ,         TF-IDF scores: 0.561 \n",
      "feature word: trumka ,         TF-IDF scores: 0.582 \n",
      "feature word: adverts ,         TF-IDF scores: 0.553 \n",
      "feature word: robot ,         TF-IDF scores: 0.546 \n",
      "feature word: robots ,         TF-IDF scores: 0.531 \n",
      "feature word: neera ,         TF-IDF scores: 0.573 \n",
      "feature word: tanden ,         TF-IDF scores: 0.564 \n",
      "feature word: kasich ,         TF-IDF scores: 0.587 \n",
      "feature word: iowa ,         TF-IDF scores: 0.505 \n",
      "feature word: iran ,         TF-IDF scores: 0.549 \n",
      "feature word: netflix ,         TF-IDF scores: 0.585 \n",
      "feature word: usa ,         TF-IDF scores: 0.578 \n",
      "feature word: banana ,         TF-IDF scores: 0.557 \n",
      "feature word: wiki ,         TF-IDF scores: 0.594 \n",
      "feature word: debt ,         TF-IDF scores: 0.522 \n",
      "feature word: lynch ,         TF-IDF scores: 0.59 \n",
      "feature word: vhs ,         TF-IDF scores: 0.543 \n",
      "feature word: drudge ,         TF-IDF scores: 0.547 \n",
      "feature word: robbery ,         TF-IDF scores: 0.553 \n",
      "feature word: walmart ,         TF-IDF scores: 0.553 \n",
      "feature word: metaxas ,         TF-IDF scores: 0.541 \n",
      "feature word: miracles ,         TF-IDF scores: 0.532 \n",
      "feature word: koch ,         TF-IDF scores: 0.596 \n",
      "feature word: art ,         TF-IDF scores: 0.569 \n",
      "feature word: embargo ,         TF-IDF scores: 0.541 \n",
      "feature word: utah ,         TF-IDF scores: 0.586 \n",
      "feature word: carts ,         TF-IDF scores: 0.509 \n",
      "feature word: slows ,         TF-IDF scores: 0.555 \n",
      "feature word: va ,         TF-IDF scores: 0.562 \n",
      "feature word: isis ,         TF-IDF scores: 0.509 \n",
      "feature word: duckworth ,         TF-IDF scores: 0.58 \n",
      "feature word: healthcare ,         TF-IDF scores: 0.589 \n",
      "feature word: rubio ,         TF-IDF scores: 0.501 \n",
      "feature word: kirby ,         TF-IDF scores: 0.564 \n",
      "feature word: carrot ,         TF-IDF scores: 0.517 \n",
      "feature word: stealth ,         TF-IDF scores: 0.527 \n",
      "feature word: abridged ,         TF-IDF scores: 0.529 \n",
      "feature word: financing ,         TF-IDF scores: 0.511 \n",
      "feature word: obamacare ,         TF-IDF scores: 0.501 \n",
      "feature word: gaming ,         TF-IDF scores: 0.525 \n",
      "feature word: mosul ,         TF-IDF scores: 0.513 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.512 \n",
      "feature word: carson ,         TF-IDF scores: 0.593 \n",
      "feature word: trampolining ,         TF-IDF scores: 0.512 \n",
      "feature word: opec ,         TF-IDF scores: 0.516 \n",
      "feature word: core ,         TF-IDF scores: 0.509 \n",
      "feature word: crops ,         TF-IDF scores: 0.568 \n",
      "feature word: migrants ,         TF-IDF scores: 0.51 \n",
      "feature word: flowers ,         TF-IDF scores: 0.524 \n",
      "feature word: trade ,         TF-IDF scores: 0.553 \n",
      "feature word: sanders ,         TF-IDF scores: 0.578 \n",
      "feature word: saakashvili ,         TF-IDF scores: 0.54 \n",
      "feature word: contrarian ,         TF-IDF scores: 0.568 \n",
      "feature word: melania ,         TF-IDF scores: 0.584 \n",
      "feature word: comey ,         TF-IDF scores: 0.58 \n",
      "feature word: inc ,         TF-IDF scores: 0.581 \n",
      "feature word: pains ,         TF-IDF scores: 0.516 \n",
      "feature word: prices ,         TF-IDF scores: 0.583 \n",
      "feature word: indicted ,         TF-IDF scores: 0.552 \n",
      "feature word: disturbances ,         TF-IDF scores: 0.51 \n",
      "feature word: album ,         TF-IDF scores: 0.534 \n",
      "feature word: gingrich ,         TF-IDF scores: 0.513 \n",
      "feature word: parenthood ,         TF-IDF scores: 0.505 \n",
      "feature word: calais ,         TF-IDF scores: 0.507 \n",
      "feature word: jungle ,         TF-IDF scores: 0.52 \n",
      "feature word: kyle ,         TF-IDF scores: 0.532 \n",
      "feature word: india-based ,         TF-IDF scores: 0.587 \n",
      "feature word: kasich ,         TF-IDF scores: 0.569 \n",
      "feature word: dowd ,         TF-IDF scores: 0.599 \n",
      "feature word: maureen ,         TF-IDF scores: 0.582 \n",
      "feature word: cuba ,         TF-IDF scores: 0.582 \n",
      "feature word: delegation ,         TF-IDF scores: 0.507 \n",
      "feature word: 16-year-old ,         TF-IDF scores: 0.57 \n",
      "feature word: onpolitics ,         TF-IDF scores: 0.526 \n",
      "feature word: zakharova ,         TF-IDF scores: 0.59 \n",
      "feature word: foundation ,         TF-IDF scores: 0.533 \n",
      "feature word: boehner ,         TF-IDF scores: 0.562 \n",
      "feature word: mccarthy ,         TF-IDF scores: 0.546 \n",
      "feature word: paradoxroutine ,         TF-IDF scores: 0.532 \n",
      "feature word: merger ,         TF-IDF scores: 0.525 \n",
      "feature word: romney ,         TF-IDF scores: 0.573 \n",
      "feature word: iraqi ,         TF-IDF scores: 0.549 \n",
      "feature word: thomas ,         TF-IDF scores: 0.55 \n",
      "feature word: drill ,         TF-IDF scores: 0.515 \n",
      "feature word: vodka ,         TF-IDF scores: 0.538 \n",
      "feature word: aristocracy ,         TF-IDF scores: 0.504 \n",
      "feature word: trunews ,         TF-IDF scores: 0.506 \n",
      "feature word: veterans ,         TF-IDF scores: 0.53 \n",
      "feature word: drones ,         TF-IDF scores: 0.551 \n",
      "feature word: mayor ,         TF-IDF scores: 0.511 \n",
      "feature word: jane ,         TF-IDF scores: 0.513 \n",
      "feature word: bush ,         TF-IDF scores: 0.549 \n",
      "feature word: warns ,         TF-IDF scores: 0.562 \n",
      "feature word: clarke ,         TF-IDF scores: 0.541 \n",
      "feature word: israel ,         TF-IDF scores: 0.565 \n",
      "feature word: zika ,         TF-IDF scores: 0.567 \n",
      "feature word: farming ,         TF-IDF scores: 0.505 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.535 \n",
      "feature word: quayle ,         TF-IDF scores: 0.544 \n",
      "feature word: hispanic ,         TF-IDF scores: 0.572 \n",
      "feature word: letter ,         TF-IDF scores: 0.507 \n",
      "feature word: atlantis ,         TF-IDF scores: 0.574 \n",
      "feature word: chaffetz ,         TF-IDF scores: 0.573 \n",
      "feature word: greece ,         TF-IDF scores: 0.506 \n",
      "feature word: king ,         TF-IDF scores: 0.534 \n",
      "feature word: disorder ,         TF-IDF scores: 0.525 \n",
      "feature word: contact ,         TF-IDF scores: 0.514 \n",
      "feature word: economists ,         TF-IDF scores: 0.568 \n",
      "feature word: walker ,         TF-IDF scores: 0.527 \n",
      "feature word: foval ,         TF-IDF scores: 0.559 \n",
      "feature word: incoming ,         TF-IDF scores: 0.53 \n",
      "feature word: tsunami ,         TF-IDF scores: 0.573 \n",
      "feature word: gowdy ,         TF-IDF scores: 0.506 \n",
      "feature word: trey ,         TF-IDF scores: 0.506 \n",
      "feature word: cruz ,         TF-IDF scores: 0.54 \n",
      "feature word: rubio ,         TF-IDF scores: 0.517 \n",
      "feature word: anti-jihad ,         TF-IDF scores: 0.531 \n",
      "feature word: nepal ,         TF-IDF scores: 0.585 \n",
      "feature word: cruz ,         TF-IDF scores: 0.559 \n",
      "feature word: cuba ,         TF-IDF scores: 0.53 \n",
      "feature word: gambit ,         TF-IDF scores: 0.518 \n",
      "feature word: australian ,         TF-IDF scores: 0.533 \n",
      "feature word: obama ,         TF-IDF scores: 0.551 \n",
      "feature word: clinics ,         TF-IDF scores: 0.533 \n",
      "feature word: camps ,         TF-IDF scores: 0.563 \n",
      "feature word: braces ,         TF-IDF scores: 0.521 \n",
      "feature word: nail-biter ,         TF-IDF scores: 0.573 \n",
      "feature word: secede ,         TF-IDF scores: 0.506 \n",
      "feature word: guns ,         TF-IDF scores: 0.514 \n",
      "feature word: iran ,         TF-IDF scores: 0.511 \n",
      "feature word: chena ,         TF-IDF scores: 0.56 \n",
      "feature word: juggle ,         TF-IDF scores: 0.544 \n",
      "feature word: islamic ,         TF-IDF scores: 0.514 \n",
      "feature word: clarke ,         TF-IDF scores: 0.529 \n",
      "feature word: bullying ,         TF-IDF scores: 0.578 \n",
      "feature word: indiana ,         TF-IDF scores: 0.551 \n",
      "feature word: rubio ,         TF-IDF scores: 0.569 \n",
      "feature word: yelp ,         TF-IDF scores: 0.589 \n",
      "feature word: conundrum ,         TF-IDF scores: 0.561 \n",
      "feature word: kenya ,         TF-IDF scores: 0.514 \n",
      "feature word: baltic ,         TF-IDF scores: 0.528 \n",
      "feature word: hybrid ,         TF-IDF scores: 0.564 \n",
      "feature word: buildings ,         TF-IDF scores: 0.502 \n",
      "feature word: williams ,         TF-IDF scores: 0.512 \n",
      "feature word: helicopter ,         TF-IDF scores: 0.567 \n",
      "feature word: presenter ,         TF-IDF scores: 0.575 \n",
      "feature word: kickboxing ,         TF-IDF scores: 0.515 \n",
      "feature word: yemenis ,         TF-IDF scores: 0.505 \n",
      "feature word: african ,         TF-IDF scores: 0.562 \n",
      "feature word: directive ,         TF-IDF scores: 0.522 \n",
      "feature word: al-qaeda ,         TF-IDF scores: 0.507 \n",
      "feature word: gold ,         TF-IDF scores: 0.539 \n",
      "feature word: coin ,         TF-IDF scores: 0.568 \n",
      "feature word: rnc ,         TF-IDF scores: 0.534 \n",
      "feature word: film ,         TF-IDF scores: 0.56 \n",
      "feature word: password ,         TF-IDF scores: 0.569 \n",
      "feature word: pool ,         TF-IDF scores: 0.569 \n",
      "feature word: iran ,         TF-IDF scores: 0.592 \n",
      "feature word: fbi ,         TF-IDF scores: 0.511 \n",
      "feature word: sinjar ,         TF-IDF scores: 0.584 \n",
      "feature word: cell ,         TF-IDF scores: 0.512 \n",
      "feature word: yuengling ,         TF-IDF scores: 0.588 \n",
      "feature word: hannity ,         TF-IDF scores: 0.591 \n",
      "feature word: sean ,         TF-IDF scores: 0.503 \n",
      "feature word: non-mainstream ,         TF-IDF scores: 0.569 \n",
      "feature word: stossel ,         TF-IDF scores: 0.574 \n",
      "feature word: @ ,         TF-IDF scores: 0.506 \n",
      "feature word: potus ,         TF-IDF scores: 0.539 \n",
      "feature word: illness ,         TF-IDF scores: 0.518 \n",
      "feature word: mental ,         TF-IDF scores: 0.504 \n",
      "feature word: francis ,         TF-IDF scores: 0.587 \n",
      "feature word: pope ,         TF-IDF scores: 0.514 \n",
      "feature word: kasich ,         TF-IDF scores: 0.514 \n",
      "feature word: bathroom ,         TF-IDF scores: 0.55 \n",
      "feature word: deutsche ,         TF-IDF scores: 0.539 \n",
      "feature word: sanders ,         TF-IDF scores: 0.595 \n",
      "feature word: endgame ,         TF-IDF scores: 0.593 \n",
      "feature word: lynch ,         TF-IDF scores: 0.505 \n",
      "feature word: gold ,         TF-IDF scores: 0.586 \n",
      "feature word: smoking ,         TF-IDF scores: 0.532 \n",
      "feature word: hampshire ,         TF-IDF scores: 0.55 \n",
      "feature word: irs ,         TF-IDF scores: 0.567 \n",
      "feature word: patients ,         TF-IDF scores: 0.51 \n",
      "feature word: • ,         TF-IDF scores: 0.596 \n",
      "feature word: flowers ,         TF-IDF scores: 0.514 \n",
      "feature word: chicago ,         TF-IDF scores: 0.547 \n",
      "feature word: library ,         TF-IDF scores: 0.533 \n",
      "feature word: christie ,         TF-IDF scores: 0.583 \n",
      "feature word: tradesman ,         TF-IDF scores: 0.558 \n",
      "feature word: jordan ,         TF-IDF scores: 0.58 \n",
      "feature word: guantanamo ,         TF-IDF scores: 0.537 \n",
      "feature word: merkel ,         TF-IDF scores: 0.547 \n",
      "feature word: pelosi ,         TF-IDF scores: 0.509 \n",
      "feature word: sanders ,         TF-IDF scores: 0.517 \n",
      "feature word: gold ,         TF-IDF scores: 0.507 \n",
      "feature word: delegates ,         TF-IDF scores: 0.585 \n",
      "feature word: cruz ,         TF-IDF scores: 0.517 \n",
      "feature word: draftourdaughters ,         TF-IDF scores: 0.559 \n",
      "feature word: campus ,         TF-IDF scores: 0.501 \n",
      "feature word: cuba ,         TF-IDF scores: 0.572 \n",
      "feature word: prices ,         TF-IDF scores: 0.502 \n",
      "feature word: drug ,         TF-IDF scores: 0.542 \n",
      "feature word: conway ,         TF-IDF scores: 0.559 \n",
      "feature word: anglin ,         TF-IDF scores: 0.581 \n",
      "feature word: biden ,         TF-IDF scores: 0.585 \n",
      "feature word: diseases-must ,         TF-IDF scores: 0.503 \n",
      "feature word: ukip ,         TF-IDF scores: 0.571 \n",
      "feature word: mp ,         TF-IDF scores: 0.515 \n",
      "feature word: currency ,         TF-IDF scores: 0.517 \n",
      "feature word: lamb ,         TF-IDF scores: 0.563 \n",
      "feature word: oliver ,         TF-IDF scores: 0.56 \n",
      "feature word: smear ,         TF-IDF scores: 0.502 \n",
      "feature word: bison ,         TF-IDF scores: 0.517 \n",
      "feature word: assad ,         TF-IDF scores: 0.538 \n",
      "feature word: ingraham ,         TF-IDF scores: 0.549 \n",
      "feature word: sanders ,         TF-IDF scores: 0.587 \n",
      "feature word: rubio ,         TF-IDF scores: 0.535 \n",
      "feature word: duterte ,         TF-IDF scores: 0.587 \n",
      "feature word: va ,         TF-IDF scores: 0.582 \n",
      "feature word: china ,         TF-IDF scores: 0.577 \n",
      "feature word: absentee ,         TF-IDF scores: 0.523 \n",
      "feature word: walnuts ,         TF-IDF scores: 0.592 \n",
      "feature word: insist ,         TF-IDF scores: 0.591 \n",
      "feature word: rioting ,         TF-IDF scores: 0.543 \n",
      "feature word: hotel ,         TF-IDF scores: 0.573 \n",
      "feature word: korea ,         TF-IDF scores: 0.585 \n",
      "feature word: last-ditch ,         TF-IDF scores: 0.516 \n",
      "feature word: morris ,         TF-IDF scores: 0.54 \n",
      "feature word: tobacco ,         TF-IDF scores: 0.545 \n",
      "feature word: sanders ,         TF-IDF scores: 0.565 \n",
      "feature word: cruz ,         TF-IDF scores: 0.524 \n",
      "feature word: kp ,         TF-IDF scores: 0.575 \n",
      "feature word: » ,         TF-IDF scores: 0.505 \n",
      "feature word: « ,         TF-IDF scores: 0.599 \n",
      "feature word: baltimore ,         TF-IDF scores: 0.536 \n",
      "feature word: anti-semitic ,         TF-IDF scores: 0.557 \n",
      "feature word: polarization ,         TF-IDF scores: 0.589 \n",
      "feature word: tal ,         TF-IDF scores: 0.594 \n",
      "feature word: trunews ,         TF-IDF scores: 0.543 \n",
      "feature word: arteries ,         TF-IDF scores: 0.572 \n",
      "feature word: ri ,         TF-IDF scores: 0.546 \n",
      "feature word: schultz ,         TF-IDF scores: 0.526 \n",
      "feature word: wasserman ,         TF-IDF scores: 0.574 \n",
      "feature word: francis ,         TF-IDF scores: 0.516 \n",
      "feature word: pope ,         TF-IDF scores: 0.54 \n",
      "feature word: fawkes ,         TF-IDF scores: 0.538 \n",
      "feature word: tackles ,         TF-IDF scores: 0.566 \n",
      "feature word: trucks ,         TF-IDF scores: 0.585 \n",
      "feature word: warner ,         TF-IDF scores: 0.536 \n",
      "feature word: parenthood ,         TF-IDF scores: 0.549 \n",
      "feature word: eastward ,         TF-IDF scores: 0.58 \n",
      "feature word: scalia ,         TF-IDF scores: 0.597 \n",
      "feature word: baltimore ,         TF-IDF scores: 0.554 \n",
      "feature word: ashutosh ,         TF-IDF scores: 0.59 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.501 \n",
      "feature word: gold ,         TF-IDF scores: 0.555 \n",
      "feature word: sign ,         TF-IDF scores: 0.522 \n",
      "feature word: enrollment ,         TF-IDF scores: 0.544 \n",
      "feature word: baking ,         TF-IDF scores: 0.564 \n",
      "feature word: soda ,         TF-IDF scores: 0.588 \n",
      "feature word: checks ,         TF-IDF scores: 0.557 \n",
      "feature word: conservatism ,         TF-IDF scores: 0.545 \n",
      "feature word: blair ,         TF-IDF scores: 0.542 \n",
      "feature word: @ ,         TF-IDF scores: 0.562 \n",
      "feature word: renewable ,         TF-IDF scores: 0.597 \n",
      "feature word: lousy ,         TF-IDF scores: 0.54 \n",
      "feature word: christians ,         TF-IDF scores: 0.564 \n",
      "feature word: tax ,         TF-IDF scores: 0.504 \n",
      "feature word: paris ,         TF-IDF scores: 0.523 \n",
      "feature word: johnson ,         TF-IDF scores: 0.58 \n",
      "feature word: powder ,         TF-IDF scores: 0.532 \n",
      "feature word: delegates ,         TF-IDF scores: 0.531 \n",
      "feature word: pope ,         TF-IDF scores: 0.502 \n",
      "feature word: brown ,         TF-IDF scores: 0.53 \n",
      "feature word: palestinians ,         TF-IDF scores: 0.539 \n",
      "feature word: brexit ,         TF-IDF scores: 0.589 \n",
      "feature word: tesla ,         TF-IDF scores: 0.506 \n",
      "feature word: abdullah ,         TF-IDF scores: 0.572 \n",
      "feature word: nuked ,         TF-IDF scores: 0.509 \n",
      "feature word: pot ,         TF-IDF scores: 0.558 \n",
      "feature word: water ,         TF-IDF scores: 0.523 \n",
      "feature word: pharrell ,         TF-IDF scores: 0.571 \n",
      "feature word: anthem ,         TF-IDF scores: 0.583 \n",
      "feature word: fbi ,         TF-IDF scores: 0.526 \n",
      "feature word: wisconsin ,         TF-IDF scores: 0.555 \n",
      "feature word: veritas ,         TF-IDF scores: 0.503 \n",
      "feature word: paul ,         TF-IDF scores: 0.551 \n",
      "feature word: spin ,         TF-IDF scores: 0.596 \n",
      "feature word: profile ,         TF-IDF scores: 0.521 \n",
      "feature word: tonopah ,         TF-IDF scores: 0.514 \n",
      "feature word: cuban ,         TF-IDF scores: 0.501 \n",
      "feature word: mavs ,         TF-IDF scores: 0.549 \n",
      "feature word: underpins ,         TF-IDF scores: 0.579 \n",
      "feature word: cabinet ,         TF-IDF scores: 0.535 \n",
      "feature word: trade ,         TF-IDF scores: 0.523 \n",
      "feature word: costumes ,         TF-IDF scores: 0.549 \n",
      "feature word: putins ,         TF-IDF scores: 0.597 \n",
      "feature word: maduro ,         TF-IDF scores: 0.59 \n",
      "feature word: flexes ,         TF-IDF scores: 0.551 \n",
      "feature word: kardashian ,         TF-IDF scores: 0.578 \n",
      "feature word: veto ,         TF-IDF scores: 0.502 \n",
      "feature word: koch ,         TF-IDF scores: 0.532 \n",
      "feature word: consistent ,         TF-IDF scores: 0.579 \n",
      "feature word: giuliani ,         TF-IDF scores: 0.512 \n",
      "feature word: apartheid ,         TF-IDF scores: 0.531 \n",
      "feature word: 'affirmative ,         TF-IDF scores: 0.542 \n",
      "feature word: palestinian ,         TF-IDF scores: 0.512 \n",
      "feature word: comey ,         TF-IDF scores: 0.519 \n",
      "feature word: gun ,         TF-IDF scores: 0.524 \n",
      "feature word: pakistan ,         TF-IDF scores: 0.526 \n",
      "feature word: isi ,         TF-IDF scores: 0.576 \n",
      "feature word: millennials ,         TF-IDF scores: 0.582 \n",
      "feature word: bush ,         TF-IDF scores: 0.565 \n",
      "feature word: bush ,         TF-IDF scores: 0.513 \n",
      "feature word: protesters ,         TF-IDF scores: 0.59 \n",
      "feature word: schultz ,         TF-IDF scores: 0.593 \n",
      "feature word: potatoes ,         TF-IDF scores: 0.578 \n",
      "feature word: insist ,         TF-IDF scores: 0.51 \n",
      "feature word: territorial ,         TF-IDF scores: 0.521 \n",
      "feature word: ballot ,         TF-IDF scores: 0.547 \n",
      "feature word: eye ,         TF-IDF scores: 0.549 \n",
      "feature word: mexicans ,         TF-IDF scores: 0.568 \n",
      "feature word: wyoming ,         TF-IDF scores: 0.551 \n",
      "feature word: israel ,         TF-IDF scores: 0.536 \n",
      "feature word: staffers ,         TF-IDF scores: 0.574 \n",
      "feature word: enlistment ,         TF-IDF scores: 0.522 \n",
      "feature word: sue ,         TF-IDF scores: 0.526 \n",
      "feature word: trump ,         TF-IDF scores: 0.515 \n",
      "feature word: hebdo ,         TF-IDF scores: 0.554 \n",
      "feature word: swansea ,         TF-IDF scores: 0.518 \n",
      "feature word: spectre ,         TF-IDF scores: 0.54 \n",
      "feature word: melania ,         TF-IDF scores: 0.591 \n",
      "feature word: lamb ,         TF-IDF scores: 0.57 \n",
      "feature word: delta ,         TF-IDF scores: 0.516 \n",
      "feature word: blitz ,         TF-IDF scores: 0.518 \n",
      "feature word: tonight ,         TF-IDF scores: 0.503 \n",
      "feature word: christie ,         TF-IDF scores: 0.512 \n",
      "feature word: climate ,         TF-IDF scores: 0.524 \n",
      "feature word: calais ,         TF-IDF scores: 0.508 \n",
      "feature word: moon ,         TF-IDF scores: 0.535 \n",
      "feature word: scorpio ,         TF-IDF scores: 0.597 \n",
      "feature word: delegates ,         TF-IDF scores: 0.55 \n",
      "feature word: jets ,         TF-IDF scores: 0.505 \n",
      "feature word: doctors ,         TF-IDF scores: 0.535 \n",
      "feature word: bonfire ,         TF-IDF scores: 0.523 \n",
      "feature word: glyphosate ,         TF-IDF scores: 0.541 \n",
      "feature word: dilemma ,         TF-IDF scores: 0.513 \n",
      "feature word: head-first ,         TF-IDF scores: 0.521 \n",
      "feature word: symbol ,         TF-IDF scores: 0.537 \n",
      "feature word: comey ,         TF-IDF scores: 0.506 \n",
      "feature word: rubio ,         TF-IDF scores: 0.592 \n",
      "feature word: hand ,         TF-IDF scores: 0.549 \n",
      "feature word: fits ,         TF-IDF scores: 0.537 \n",
      "feature word: steel ,         TF-IDF scores: 0.578 \n",
      "feature word: temple ,         TF-IDF scores: 0.586 \n",
      "feature word: privilege ,         TF-IDF scores: 0.522 \n",
      "feature word: businesses ,         TF-IDF scores: 0.554 \n",
      "feature word: mosque ,         TF-IDF scores: 0.543 \n",
      "feature word: langelle ,         TF-IDF scores: 0.576 \n",
      "feature word: sanders ,         TF-IDF scores: 0.522 \n",
      "feature word: gold ,         TF-IDF scores: 0.524 \n",
      "feature word: u ,         TF-IDF scores: 0.52 \n",
      "feature word: zarif ,         TF-IDF scores: 0.595 \n",
      "feature word: adams ,         TF-IDF scores: 0.563 \n",
      "feature word: clintons ,         TF-IDF scores: 0.577 \n",
      "feature word: ketogenic ,         TF-IDF scores: 0.583 \n",
      "feature word: trunews ,         TF-IDF scores: 0.559 \n",
      "feature word: councillor ,         TF-IDF scores: 0.571 \n",
      "feature word: cruz ,         TF-IDF scores: 0.585 \n",
      "feature word: ryan ,         TF-IDF scores: 0.555 \n",
      "feature word: neocons ,         TF-IDF scores: 0.514 \n",
      "feature word: peacemaker ,         TF-IDF scores: 0.555 \n",
      "feature word: california ,         TF-IDF scores: 0.524 \n",
      "feature word: armenians ,         TF-IDF scores: 0.523 \n",
      "feature word: fretting ,         TF-IDF scores: 0.535 \n",
      "feature word: al-qaeda ,         TF-IDF scores: 0.598 \n",
      "feature word: dakota ,         TF-IDF scores: 0.561 \n",
      "feature word: bishop ,         TF-IDF scores: 0.529 \n",
      "feature word: wales ,         TF-IDF scores: 0.58 \n",
      "feature word: malley ,         TF-IDF scores: 0.569 \n",
      "feature word: ryan ,         TF-IDF scores: 0.593 \n",
      "feature word: star ,         TF-IDF scores: 0.538 \n",
      "feature word: cleveland ,         TF-IDF scores: 0.54 \n",
      "feature word: msm ,         TF-IDF scores: 0.559 \n",
      "feature word: cronyistic ,         TF-IDF scores: 0.501 \n",
      "feature word: mormons ,         TF-IDF scores: 0.569 \n",
      "feature word: prohibition ,         TF-IDF scores: 0.581 \n",
      "feature word: onpolitics ,         TF-IDF scores: 0.503 \n",
      "feature word: cabinet ,         TF-IDF scores: 0.562 \n",
      "feature word: judges ,         TF-IDF scores: 0.586 \n",
      "feature word: budget ,         TF-IDF scores: 0.565 \n",
      "feature word: sanders ,         TF-IDF scores: 0.521 \n",
      "feature word: winter ,         TF-IDF scores: 0.53 \n",
      "feature word: jeb ,         TF-IDF scores: 0.53 \n",
      "feature word: bush ,         TF-IDF scores: 0.567 \n",
      "feature word: ww3 ,         TF-IDF scores: 0.571 \n",
      "feature word: mall ,         TF-IDF scores: 0.546 \n",
      "feature word: muslims ,         TF-IDF scores: 0.57 \n",
      "feature word: lockheed ,         TF-IDF scores: 0.549 \n",
      "feature word: egyptian ,         TF-IDF scores: 0.596 \n",
      "feature word: netflix ,         TF-IDF scores: 0.529 \n",
      "feature word: sovereign ,         TF-IDF scores: 0.504 \n",
      "feature word: border ,         TF-IDF scores: 0.536 \n",
      "feature word: kim ,         TF-IDF scores: 0.58 \n",
      "feature word: raqqa ,         TF-IDF scores: 0.55 \n",
      "feature word: cattle ,         TF-IDF scores: 0.553 \n",
      "feature word: gohmert ,         TF-IDF scores: 0.506 \n",
      "feature word: splits ,         TF-IDF scores: 0.508 \n",
      "feature word: creamer ,         TF-IDF scores: 0.554 \n",
      "feature word: auditors ,         TF-IDF scores: 0.541 \n",
      "feature word: 30th ,         TF-IDF scores: 0.529 \n",
      "feature word: co-worker ,         TF-IDF scores: 0.587 \n",
      "feature word: furniture ,         TF-IDF scores: 0.56 \n",
      "feature word: wwiii ,         TF-IDF scores: 0.53 \n",
      "feature word: pirate ,         TF-IDF scores: 0.549 \n",
      "feature word: carson ,         TF-IDF scores: 0.56 \n",
      "feature word: aids ,         TF-IDF scores: 0.57 \n",
      "feature word: va ,         TF-IDF scores: 0.53 \n",
      "feature word: campus ,         TF-IDF scores: 0.512 \n",
      "feature word: nintendo ,         TF-IDF scores: 0.509 \n",
      "feature word: magazines ,         TF-IDF scores: 0.519 \n",
      "feature word: beer ,         TF-IDF scores: 0.505 \n",
      "feature word: pisstake ,         TF-IDF scores: 0.57 \n",
      "feature word: marriage ,         TF-IDF scores: 0.584 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.543 \n",
      "feature word: iran ,         TF-IDF scores: 0.571 \n",
      "feature word: veterans ,         TF-IDF scores: 0.581 \n",
      "feature word: ships ,         TF-IDF scores: 0.54 \n",
      "feature word: glyphosate ,         TF-IDF scores: 0.572 \n",
      "feature word: sexier ,         TF-IDF scores: 0.598 \n",
      "feature word: boehner ,         TF-IDF scores: 0.506 \n",
      "feature word: mosul ,         TF-IDF scores: 0.593 \n",
      "feature word: serco ,         TF-IDF scores: 0.538 \n",
      "feature word: detention ,         TF-IDF scores: 0.507 \n",
      "feature word: cancer ,         TF-IDF scores: 0.505 \n",
      "feature word: meat ,         TF-IDF scores: 0.583 \n",
      "feature word: dollar ,         TF-IDF scores: 0.534 \n",
      "feature word: bitter ,         TF-IDF scores: 0.521 \n",
      "feature word: veterans ,         TF-IDF scores: 0.546 \n",
      "feature word: emails ,         TF-IDF scores: 0.52 \n",
      "feature word: markle ,         TF-IDF scores: 0.567 \n",
      "feature word: mosul ,         TF-IDF scores: 0.545 \n",
      "feature word: iran ,         TF-IDF scores: 0.512 \n",
      "feature word: islamic ,         TF-IDF scores: 0.527 \n",
      "feature word: church ,         TF-IDF scores: 0.579 \n",
      "feature word: police ,         TF-IDF scores: 0.503 \n",
      "feature word: zarif ,         TF-IDF scores: 0.54 \n",
      "feature word: belgian ,         TF-IDF scores: 0.528 \n",
      "feature word: eczema ,         TF-IDF scores: 0.51 \n",
      "feature word: cruz ,         TF-IDF scores: 0.53 \n",
      "feature word: doe ,         TF-IDF scores: 0.501 \n",
      "feature word: mi5 ,         TF-IDF scores: 0.547 \n",
      "feature word: gold ,         TF-IDF scores: 0.536 \n",
      "feature word: batteries ,         TF-IDF scores: 0.548 \n",
      "feature word: vets ,         TF-IDF scores: 0.529 \n",
      "feature word: emails ,         TF-IDF scores: 0.553 \n",
      "feature word: israel ,         TF-IDF scores: 0.57 \n",
      "feature word: paul ,         TF-IDF scores: 0.574 \n",
      "feature word: superdelegates ,         TF-IDF scores: 0.527 \n",
      "feature word: christie ,         TF-IDF scores: 0.568 \n",
      "feature word: defence ,         TF-IDF scores: 0.586 \n",
      "feature word: sanders ,         TF-IDF scores: 0.556 \n",
      "feature word:  ,         TF-IDF scores: 0.511 \n",
      "feature word: warren ,         TF-IDF scores: 0.576 \n",
      "feature word: hydrogen ,         TF-IDF scores: 0.585 \n",
      "feature word: delegates ,         TF-IDF scores: 0.501 \n",
      "feature word: obamacare ,         TF-IDF scores: 0.512 \n",
      "feature word: nazi ,         TF-IDF scores: 0.54 \n",
      "feature word: halloween ,         TF-IDF scores: 0.511 \n",
      "feature word: england ,         TF-IDF scores: 0.518 \n",
      "feature word: egypt ,         TF-IDF scores: 0.533 \n",
      "feature word: russia ,         TF-IDF scores: 0.533 \n",
      "feature word: rico ,         TF-IDF scores: 0.55 \n",
      "feature word: treaty ,         TF-IDF scores: 0.577 \n",
      "feature word: street/washington ,         TF-IDF scores: 0.582 \n",
      "feature word: kochs ,         TF-IDF scores: 0.587 \n",
      "feature word: hate ,         TF-IDF scores: 0.541 \n",
      "feature word: sex ,         TF-IDF scores: 0.529 \n",
      "feature word: clearance ,         TF-IDF scores: 0.543 \n",
      "feature word: buzzfeed ,         TF-IDF scores: 0.504 \n",
      "feature word: biden ,         TF-IDF scores: 0.54 \n",
      "feature word: armstrong ,         TF-IDF scores: 0.59 \n",
      "feature word: bill ,         TF-IDF scores: 0.51 \n",
      "feature word: scrambles ,         TF-IDF scores: 0.55 \n",
      "feature word: sanders ,         TF-IDF scores: 0.591 \n",
      "feature word: carter ,         TF-IDF scores: 0.52 \n",
      "feature word: scalia ,         TF-IDF scores: 0.579 \n",
      "feature word: religious ,         TF-IDF scores: 0.502 \n",
      "feature word: condell ,         TF-IDF scores: 0.517 \n",
      "feature word: englishman ,         TF-IDF scores: 0.562 \n",
      "feature word: podesta ,         TF-IDF scores: 0.551 \n",
      "feature word: fbi ,         TF-IDF scores: 0.53 \n",
      "feature word: totalitarian ,         TF-IDF scores: 0.531 \n",
      "feature word: tsarnaev ,         TF-IDF scores: 0.566 \n",
      "feature word: beef ,         TF-IDF scores: 0.524 \n",
      "feature word: sanders ,         TF-IDF scores: 0.556 \n",
      "feature word: sanders ,         TF-IDF scores: 0.586 \n",
      "feature word: registration ,         TF-IDF scores: 0.532 \n",
      "feature word: mcconnell ,         TF-IDF scores: 0.557 \n",
      "feature word: neeson ,         TF-IDF scores: 0.517 \n",
      "feature word: rubio ,         TF-IDF scores: 0.541 \n",
      "feature word: anti-semitic ,         TF-IDF scores: 0.522 \n",
      "feature word: boehner ,         TF-IDF scores: 0.585 \n",
      "feature word: ramos ,         TF-IDF scores: 0.572 \n",
      "feature word: jorge ,         TF-IDF scores: 0.511 \n",
      "feature word: kashmir ,         TF-IDF scores: 0.59 \n",
      "feature word: baltimore ,         TF-IDF scores: 0.584 \n",
      "feature word: flashback ,         TF-IDF scores: 0.592 \n",
      "feature word: hotel ,         TF-IDF scores: 0.506 \n",
      "feature word: obamacare ,         TF-IDF scores: 0.509 \n",
      "feature word: citizenship ,         TF-IDF scores: 0.528 \n",
      "feature word: takei ,         TF-IDF scores: 0.523 \n",
      "feature word: fact-checking ,         TF-IDF scores: 0.57 \n",
      "feature word: trump ,         TF-IDF scores: 0.547 \n",
      "feature word: fiorina ,         TF-IDF scores: 0.557 \n",
      "feature word: ethics ,         TF-IDF scores: 0.58 \n",
      "feature word: sanders ,         TF-IDF scores: 0.54 \n",
      "feature word: weiner ,         TF-IDF scores: 0.571 \n",
      "feature word: kelly ,         TF-IDF scores: 0.581 \n",
      "feature word: holocaust ,         TF-IDF scores: 0.51 \n",
      "feature word: aumf ,         TF-IDF scores: 0.512 \n",
      "feature word: statue ,         TF-IDF scores: 0.56 \n",
      "feature word: ryan ,         TF-IDF scores: 0.542 \n",
      "feature word: va ,         TF-IDF scores: 0.553 \n",
      "feature word: mcdonald ,         TF-IDF scores: 0.548 \n",
      "feature word: belgium ,         TF-IDF scores: 0.582 \n",
      "feature word: sanders ,         TF-IDF scores: 0.597 \n",
      "feature word: castro ,         TF-IDF scores: 0.524 \n",
      "feature word: gun ,         TF-IDF scores: 0.548 \n",
      "feature word: expectancy ,         TF-IDF scores: 0.55 \n",
      "feature word: brexit ,         TF-IDF scores: 0.539 \n",
      "feature word: fellas ,         TF-IDF scores: 0.556 \n",
      "feature word: fiorina ,         TF-IDF scores: 0.529 \n",
      "feature word: ryan ,         TF-IDF scores: 0.592 \n",
      "feature word: watson ,         TF-IDF scores: 0.53 \n",
      "feature word: ferguson ,         TF-IDF scores: 0.599 \n",
      "feature word: voting ,         TF-IDF scores: 0.531 \n",
      "feature word: mental ,         TF-IDF scores: 0.507 \n",
      "feature word: christie ,         TF-IDF scores: 0.517 \n",
      "feature word: bannon ,         TF-IDF scores: 0.571 \n",
      "feature word: indiana ,         TF-IDF scores: 0.51 \n",
      "feature word: quadruples ,         TF-IDF scores: 0.509 \n",
      "feature word: gelatin ,         TF-IDF scores: 0.521 \n",
      "feature word: bug ,         TF-IDF scores: 0.531 \n",
      "feature word: third-world ,         TF-IDF scores: 0.597 \n",
      "feature word: biden ,         TF-IDF scores: 0.547 \n",
      "feature word: nuland ,         TF-IDF scores: 0.566 \n",
      "feature word: gay ,         TF-IDF scores: 0.587 \n",
      "feature word: holly ,         TF-IDF scores: 0.59 \n",
      "feature word: vendetta ,         TF-IDF scores: 0.546 \n",
      "feature word: abortion ,         TF-IDF scores: 0.566 \n",
      "feature word: sanders ,         TF-IDF scores: 0.569 \n",
      "feature word: electrify ,         TF-IDF scores: 0.56 \n",
      "feature word: highway ,         TF-IDF scores: 0.501 \n",
      "feature word: pac ,         TF-IDF scores: 0.564 \n",
      "feature word: mosul ,         TF-IDF scores: 0.514 \n",
      "feature word: obamacare ,         TF-IDF scores: 0.514 \n",
      "feature word: ebola ,         TF-IDF scores: 0.54 \n",
      "feature word: hebrew ,         TF-IDF scores: 0.553 \n",
      "feature word: daesh ,         TF-IDF scores: 0.529 \n",
      "feature word: eyes ,         TF-IDF scores: 0.509 \n",
      "feature word: tax ,         TF-IDF scores: 0.517 \n",
      "feature word: mosque ,         TF-IDF scores: 0.543 \n",
      "feature word: mcconnell ,         TF-IDF scores: 0.586 \n",
      "feature word: zambrano-montes ,         TF-IDF scores: 0.519 \n",
      "feature word: migrants ,         TF-IDF scores: 0.517 \n",
      "feature word: scalia ,         TF-IDF scores: 0.57 \n",
      "feature word: onion ,         TF-IDF scores: 0.576 \n",
      "feature word: rt ,         TF-IDF scores: 0.593 \n",
      "feature word: stares ,         TF-IDF scores: 0.545 \n",
      "feature word: julian ,         TF-IDF scores: 0.556 \n",
      "feature word: cruz ,         TF-IDF scores: 0.591 \n",
      "feature word: gulf ,         TF-IDF scores: 0.521 \n",
      "feature word: wikileakes ,         TF-IDF scores: 0.555 \n",
      "feature word: italy ,         TF-IDF scores: 0.507 \n",
      "feature word: patent ,         TF-IDF scores: 0.52 \n",
      "feature word: mexico ,         TF-IDF scores: 0.587 \n",
      "feature word: x ,         TF-IDF scores: 0.527 \n",
      "feature word: mccain ,         TF-IDF scores: 0.522 \n",
      "feature word: mushroom ,         TF-IDF scores: 0.59 \n",
      "feature word: carson ,         TF-IDF scores: 0.587 \n",
      "feature word: khan ,         TF-IDF scores: 0.518 \n",
      "feature word: bush ,         TF-IDF scores: 0.575 \n",
      "feature word: iran ,         TF-IDF scores: 0.581 \n",
      "feature word: mental ,         TF-IDF scores: 0.524 \n",
      "feature word: cave ,         TF-IDF scores: 0.567 \n",
      "feature word: kenya ,         TF-IDF scores: 0.576 \n",
      "feature word: sanders ,         TF-IDF scores: 0.55 \n",
      "feature word: iowa ,         TF-IDF scores: 0.542 \n",
      "feature word: lynch ,         TF-IDF scores: 0.53 \n",
      "feature word: stock ,         TF-IDF scores: 0.594 \n",
      "feature word: nefarium ,         TF-IDF scores: 0.551 \n",
      "feature word: barage ,         TF-IDF scores: 0.544 \n",
      "feature word: billary ,         TF-IDF scores: 0.544 \n",
      "feature word: cocaine ,         TF-IDF scores: 0.547 \n",
      "feature word: contraception ,         TF-IDF scores: 0.528 \n",
      "feature word: damage-control ,         TF-IDF scores: 0.563 \n",
      "feature word: spills ,         TF-IDF scores: 0.514 \n",
      "feature word: speeches ,         TF-IDF scores: 0.556 \n",
      "feature word: penalty ,         TF-IDF scores: 0.519 \n",
      "feature word: romney ,         TF-IDF scores: 0.515 \n",
      "feature word: kasich ,         TF-IDF scores: 0.557 \n",
      "feature word: shootings ,         TF-IDF scores: 0.584 \n",
      "feature word: mass ,         TF-IDF scores: 0.502 \n",
      "feature word: montenegro ,         TF-IDF scores: 0.522 \n",
      "feature word: oligarchs ,         TF-IDF scores: 0.543 \n",
      "feature word: kenya ,         TF-IDF scores: 0.509 \n",
      "feature word: 36-thestoryofjesus ,         TF-IDF scores: 0.544 \n",
      "feature word: bosanski ,         TF-IDF scores: 0.544 \n",
      "feature word: prijevod ,         TF-IDF scores: 0.544 \n",
      "feature word: jews ,         TF-IDF scores: 0.594 \n",
      "feature word: marriage ,         TF-IDF scores: 0.564 \n",
      "feature word: podesta ,         TF-IDF scores: 0.516 \n",
      "feature word: units ,         TF-IDF scores: 0.558 \n",
      "feature word: biometric ,         TF-IDF scores: 0.513 \n",
      "feature word: wikileak ,         TF-IDF scores: 0.552 \n",
      "feature word: deal ,         TF-IDF scores: 0.518 \n",
      "feature word: melania ,         TF-IDF scores: 0.501 \n",
      "feature word: border ,         TF-IDF scores: 0.569 \n",
      "feature word: gawker ,         TF-IDF scores: 0.593 \n",
      "feature word: mcmullin ,         TF-IDF scores: 0.549 \n",
      "feature word: emissions ,         TF-IDF scores: 0.586 \n",
      "feature word: suicide ,         TF-IDF scores: 0.545 \n",
      "feature word: machines ,         TF-IDF scores: 0.505 \n",
      "feature word: scary ,         TF-IDF scores: 0.546 \n",
      "feature word: seniors ,         TF-IDF scores: 0.568 \n",
      "feature word: scalia ,         TF-IDF scores: 0.529 \n",
      "feature word: johnson ,         TF-IDF scores: 0.506 \n",
      "feature word: vine ,         TF-IDF scores: 0.576 \n",
      "feature word: measles ,         TF-IDF scores: 0.541 \n",
      "feature word: vaccination ,         TF-IDF scores: 0.515 \n",
      "feature word: flowers ,         TF-IDF scores: 0.518 \n",
      "feature word: discrimination ,         TF-IDF scores: 0.516 \n",
      "feature word: duterte ,         TF-IDF scores: 0.532 \n",
      "feature word: saudi ,         TF-IDF scores: 0.54 \n",
      "feature word: cooper ,         TF-IDF scores: 0.587 \n",
      "feature word: chinese ,         TF-IDF scores: 0.565 \n",
      "feature word: onpolitics ,         TF-IDF scores: 0.503 \n",
      "feature word: cabinet ,         TF-IDF scores: 0.562 \n",
      "feature word: fraud ,         TF-IDF scores: 0.57 \n",
      "feature word: energy ,         TF-IDF scores: 0.502 \n",
      "feature word: kasich ,         TF-IDF scores: 0.506 \n",
      "feature word: michelle ,         TF-IDF scores: 0.524 \n",
      "feature word: pipeline ,         TF-IDF scores: 0.528 \n",
      "feature word: johnson ,         TF-IDF scores: 0.54 \n",
      "feature word: korea ,         TF-IDF scores: 0.599 \n",
      "feature word: slashes ,         TF-IDF scores: 0.566 \n",
      "feature word: alien ,         TF-IDF scores: 0.555 \n",
      "feature word: insects ,         TF-IDF scores: 0.554 \n",
      "feature word: correction ,         TF-IDF scores: 0.55 \n",
      "feature word: sbu ,         TF-IDF scores: 0.505 \n",
      "feature word: sexuality ,         TF-IDF scores: 0.513 \n",
      "feature word: jenner ,         TF-IDF scores: 0.513 \n",
      "feature word: hatch ,         TF-IDF scores: 0.516 \n",
      "feature word: ryan ,         TF-IDF scores: 0.561 \n",
      "feature word: polarization ,         TF-IDF scores: 0.55 \n",
      "feature word: native ,         TF-IDF scores: 0.54 \n",
      "feature word: ayotte ,         TF-IDF scores: 0.517 \n",
      "feature word: bush ,         TF-IDF scores: 0.553 \n",
      "feature word: gofundme ,         TF-IDF scores: 0.573 \n",
      "feature word: foundation ,         TF-IDF scores: 0.569 \n",
      "feature word: relents ,         TF-IDF scores: 0.576 \n",
      "feature word: baltimore ,         TF-IDF scores: 0.505 \n",
      "feature word: cruz ,         TF-IDF scores: 0.51 \n",
      "feature word: extraterrestrials ,         TF-IDF scores: 0.518 \n",
      "feature word: chaffetz ,         TF-IDF scores: 0.577 \n",
      "feature word: marijuana ,         TF-IDF scores: 0.521 \n",
      "feature word: cruz ,         TF-IDF scores: 0.514 \n",
      "feature word: playbooks ,         TF-IDF scores: 0.587 \n",
      "feature word: joints ,         TF-IDF scores: 0.57 \n",
      "feature word: county ,         TF-IDF scores: 0.545 \n",
      "feature word: abedin ,         TF-IDF scores: 0.546 \n",
      "feature word: concealed ,         TF-IDF scores: 0.559 \n",
      "feature word: carry ,         TF-IDF scores: 0.597 \n",
      "feature word: nurses ,         TF-IDF scores: 0.574 \n",
      "feature word: armenia ,         TF-IDF scores: 0.556 \n",
      "feature word: lockheed ,         TF-IDF scores: 0.558 \n",
      "feature word: chattanooga ,         TF-IDF scores: 0.544 \n",
      "feature word: undercover ,         TF-IDF scores: 0.512 \n",
      "feature word:  ,         TF-IDF scores: 0.549 \n",
      "feature word: split ,         TF-IDF scores: 0.501 \n",
      "feature word: card ,         TF-IDF scores: 0.545 \n",
      "feature word: @ ,         TF-IDF scores: 0.513 \n",
      "feature word: delegates ,         TF-IDF scores: 0.559 \n",
      "feature word: lewis ,         TF-IDF scores: 0.561 \n",
      "feature word: christmas ,         TF-IDF scores: 0.501 \n",
      "feature word: elaborate ,         TF-IDF scores: 0.536 \n",
      "feature word: stagnation ,         TF-IDF scores: 0.549 \n",
      "feature word: korea ,         TF-IDF scores: 0.597 \n",
      "feature word: podesta ,         TF-IDF scores: 0.538 \n",
      "feature word: ufo ,         TF-IDF scores: 0.57 \n",
      "feature word: veterans ,         TF-IDF scores: 0.598 \n",
      "feature word: limbaugh ,         TF-IDF scores: 0.566 \n",
      "feature word: amendment ,         TF-IDF scores: 0.525 \n",
      "feature word: lynch ,         TF-IDF scores: 0.542 \n",
      "feature word: halloween ,         TF-IDF scores: 0.585 \n",
      "feature word: protester ,         TF-IDF scores: 0.512 \n",
      "feature word: star ,         TF-IDF scores: 0.512 \n",
      "feature word: swing-state ,         TF-IDF scores: 0.511 \n",
      "feature word: blair ,         TF-IDF scores: 0.537 \n",
      "feature word: pope ,         TF-IDF scores: 0.541 \n",
      "feature word: johnson ,         TF-IDF scores: 0.518 \n",
      "feature word: biden ,         TF-IDF scores: 0.508 \n",
      "feature word: taliban ,         TF-IDF scores: 0.547 \n",
      "feature word: kidding ,         TF-IDF scores: 0.506 \n",
      "feature word: maduro ,         TF-IDF scores: 0.553 \n",
      "feature word: horse ,         TF-IDF scores: 0.533 \n",
      "feature word: facebook ,         TF-IDF scores: 0.566 \n",
      "feature word: ramadi ,         TF-IDF scores: 0.575 \n",
      "feature word: black ,         TF-IDF scores: 0.56 \n",
      "feature word: weather ,         TF-IDF scores: 0.525 \n",
      "feature word: abdullah ,         TF-IDF scores: 0.509 \n",
      "feature word: homicide ,         TF-IDF scores: 0.553 \n",
      "feature word: carson ,         TF-IDF scores: 0.503 \n",
      "feature word: ed ,         TF-IDF scores: 0.504 \n",
      "feature word: debt ,         TF-IDF scores: 0.542 \n",
      "feature word: church ,         TF-IDF scores: 0.513 \n",
      "feature word: software ,         TF-IDF scores: 0.56 \n",
      "feature word: rolled ,         TF-IDF scores: 0.573 \n",
      "feature word: moneyball ,         TF-IDF scores: 0.527 \n",
      "feature word: runway ,         TF-IDF scores: 0.596 \n",
      "feature word: conspiracy ,         TF-IDF scores: 0.562 \n",
      "feature word: flint ,         TF-IDF scores: 0.545 \n",
      "feature word: kelly ,         TF-IDF scores: 0.514 \n",
      "feature word: foundation ,         TF-IDF scores: 0.521 \n",
      "feature word: no-fly ,         TF-IDF scores: 0.558 \n",
      "feature word: same-sex ,         TF-IDF scores: 0.503 \n",
      "feature word: goldman ,         TF-IDF scores: 0.581 \n",
      "feature word: sachs ,         TF-IDF scores: 0.535 \n",
      "feature word: dna ,         TF-IDF scores: 0.573 \n",
      "feature word: god ,         TF-IDF scores: 0.514 \n",
      "feature word: baier ,         TF-IDF scores: 0.586 \n",
      "feature word: cbs4 ,         TF-IDF scores: 0.507 \n",
      "feature word: poorly ,         TF-IDF scores: 0.538 \n",
      "feature word: hindu ,         TF-IDF scores: 0.54 \n",
      "feature word: cholesterol ,         TF-IDF scores: 0.56 \n",
      "feature word: sanders ,         TF-IDF scores: 0.503 \n",
      "feature word: gruber ,         TF-IDF scores: 0.543 \n",
      "feature word: diversity ,         TF-IDF scores: 0.536 \n",
      "feature word: iran ,         TF-IDF scores: 0.541 \n",
      "feature word: manosphere ,         TF-IDF scores: 0.553 \n",
      "feature word: obamacare ,         TF-IDF scores: 0.547 \n",
      "feature word: surveillance ,         TF-IDF scores: 0.562 \n",
      "feature word: hatch ,         TF-IDF scores: 0.531 \n",
      "feature word: garland ,         TF-IDF scores: 0.559 \n",
      "feature word: registration ,         TF-IDF scores: 0.539 \n",
      "feature word: democracy ,         TF-IDF scores: 0.523 \n",
      "feature word: tonight ,         TF-IDF scores: 0.588 \n",
      "feature word: darkened ,         TF-IDF scores: 0.503 \n",
      "feature word: rocky ,         TF-IDF scores: 0.586 \n",
      "feature word: black ,         TF-IDF scores: 0.514 \n",
      "feature word: trampoline ,         TF-IDF scores: 0.558 \n",
      "feature word: boycott ,         TF-IDF scores: 0.538 \n",
      "feature word: ukraine ,         TF-IDF scores: 0.564 \n",
      "feature word: pumpkin ,         TF-IDF scores: 0.589 \n",
      "feature word: custard ,         TF-IDF scores: 0.568 \n",
      "feature word: vatican ,         TF-IDF scores: 0.517 \n",
      "feature word: sabotaging ,         TF-IDF scores: 0.583 \n",
      "feature word: indiana ,         TF-IDF scores: 0.525 \n",
      "feature word: cuba ,         TF-IDF scores: 0.535 \n",
      "feature word: halloween ,         TF-IDF scores: 0.572 \n",
      "feature word: costume ,         TF-IDF scores: 0.535 \n",
      "feature word: fireworks ,         TF-IDF scores: 0.545 \n",
      "feature word: jesus ,         TF-IDF scores: 0.546 \n",
      "feature word: veritas ,         TF-IDF scores: 0.505 \n",
      "feature word: delegates ,         TF-IDF scores: 0.558 \n",
      "feature word: g.o.p ,         TF-IDF scores: 0.506 \n",
      "feature word: rush ,         TF-IDF scores: 0.525 \n",
      "feature word: 'fear ,         TF-IDF scores: 0.571 \n",
      "feature word: luck ,         TF-IDF scores: 0.55 \n",
      "feature word: islamisation ,         TF-IDF scores: 0.556 \n",
      "feature word: gingrich ,         TF-IDF scores: 0.507 \n",
      "feature word: concedes ,         TF-IDF scores: 0.544 \n",
      "feature word: fbi ,         TF-IDF scores: 0.513 \n",
      "feature word: anthem ,         TF-IDF scores: 0.579 \n",
      "feature word: gold ,         TF-IDF scores: 0.538 \n",
      "feature word: court ,         TF-IDF scores: 0.549 \n",
      "feature word: iss ,         TF-IDF scores: 0.56 \n",
      "feature word: putin ,         TF-IDF scores: 0.545 \n",
      "feature word: manafort ,         TF-IDF scores: 0.577 \n",
      "feature word: christmas ,         TF-IDF scores: 0.57 \n",
      "feature word: moore ,         TF-IDF scores: 0.519 \n",
      "feature word: romney ,         TF-IDF scores: 0.574 \n",
      "feature word: angelina ,         TF-IDF scores: 0.508 \n",
      "feature word: jolie ,         TF-IDF scores: 0.508 \n",
      "feature word: sheriff ,         TF-IDF scores: 0.509 \n",
      "feature word: intimidate ,         TF-IDF scores: 0.539 \n",
      "feature word: unions ,         TF-IDF scores: 0.594 \n",
      "feature word: fiorina ,         TF-IDF scores: 0.593 \n",
      "feature word: rumble ,         TF-IDF scores: 0.564 \n",
      "feature word: coral ,         TF-IDF scores: 0.504 \n",
      "feature word: israel ,         TF-IDF scores: 0.578 \n",
      "feature word: guantanamo ,         TF-IDF scores: 0.559 \n",
      "feature word: cypriot ,         TF-IDF scores: 0.585 \n",
      "feature word: pence ,         TF-IDF scores: 0.599 \n",
      "feature word: sacked ,         TF-IDF scores: 0.577 \n",
      "feature word: oil ,         TF-IDF scores: 0.52 \n",
      "feature word: hall ,         TF-IDF scores: 0.536 \n",
      "feature word: schools ,         TF-IDF scores: 0.538 \n",
      "feature word: controlled ,         TF-IDF scores: 0.555 \n",
      "feature word: ryan ,         TF-IDF scores: 0.532 \n",
      "feature word: facepalm ,         TF-IDF scores: 0.506 \n",
      "feature word: hhs ,         TF-IDF scores: 0.506 \n",
      "feature word: elephants ,         TF-IDF scores: 0.504 \n",
      "feature word: sanctuary ,         TF-IDF scores: 0.563 \n",
      "feature word: qaeda ,         TF-IDF scores: 0.558 \n",
      "feature word: soros ,         TF-IDF scores: 0.56 \n",
      "feature word: moore ,         TF-IDF scores: 0.512 \n",
      "feature word: pilger ,         TF-IDF scores: 0.576 \n",
      "feature word: cruz ,         TF-IDF scores: 0.525 \n",
      "feature word: fiorina ,         TF-IDF scores: 0.551 \n",
      "feature word: text ,         TF-IDF scores: 0.516 \n",
      "feature word: teens ,         TF-IDF scores: 0.505 \n",
      "feature word: berkeley ,         TF-IDF scores: 0.533 \n",
      "feature word: breitbart ,         TF-IDF scores: 0.599 \n",
      "feature word: tpp ,         TF-IDF scores: 0.54 \n",
      "feature word: soccer ,         TF-IDF scores: 0.548 \n",
      "feature word: coal ,         TF-IDF scores: 0.517 \n",
      "feature word: saudi ,         TF-IDF scores: 0.545 \n",
      "feature word: romney ,         TF-IDF scores: 0.537 \n",
      "feature word: iraqis ,         TF-IDF scores: 0.529 \n",
      "feature word: dependence ,         TF-IDF scores: 0.537 \n",
      "feature word: tinder ,         TF-IDF scores: 0.519 \n",
      "feature word: meat ,         TF-IDF scores: 0.597 \n",
      "feature word: journalist ,         TF-IDF scores: 0.536 \n",
      "feature word: thanksgiving ,         TF-IDF scores: 0.576 \n",
      "feature word: bundy ,         TF-IDF scores: 0.51 \n",
      "feature word: clinton/kaine ,         TF-IDF scores: 0.535 \n",
      "feature word: iraqi ,         TF-IDF scores: 0.566 \n",
      "feature word: iran ,         TF-IDF scores: 0.53 \n",
      "feature word: derb ,         TF-IDF scores: 0.559 \n",
      "feature word: veto ,         TF-IDF scores: 0.512 \n",
      "feature word: opioid ,         TF-IDF scores: 0.531 \n",
      "feature word: expansion ,         TF-IDF scores: 0.556 \n",
      "feature word: budget ,         TF-IDF scores: 0.527 \n",
      "feature word: cuba ,         TF-IDF scores: 0.578 \n",
      "feature word: prison ,         TF-IDF scores: 0.589 \n",
      "feature word: dress ,         TF-IDF scores: 0.582 \n",
      "feature word: subsidies ,         TF-IDF scores: 0.585 \n",
      "feature word: market ,         TF-IDF scores: 0.579 \n",
      "feature word: bush ,         TF-IDF scores: 0.567 \n",
      "feature word: weeds ,         TF-IDF scores: 0.565 \n",
      "feature word: libertarian ,         TF-IDF scores: 0.569 \n",
      "feature word: 'drugs ,         TF-IDF scores: 0.579 \n",
      "feature word: snapchat ,         TF-IDF scores: 0.591 \n",
      "feature word: advocates ,         TF-IDF scores: 0.528 \n",
      "feature word: pay-to-play ,         TF-IDF scores: 0.514 \n",
      "feature word: davis ,         TF-IDF scores: 0.581 \n",
      "feature word: schools ,         TF-IDF scores: 0.566 \n",
      "feature word: charter ,         TF-IDF scores: 0.553 \n",
      "feature word: fargo ,         TF-IDF scores: 0.531 \n",
      "feature word: nepal ,         TF-IDF scores: 0.571 \n",
      "feature word: kathmandu ,         TF-IDF scores: 0.551 \n",
      "feature word: drought ,         TF-IDF scores: 0.533 \n",
      "feature word: stewart ,         TF-IDF scores: 0.516 \n",
      "feature word: hannity ,         TF-IDF scores: 0.507 \n",
      "feature word: ryan ,         TF-IDF scores: 0.568 \n",
      "feature word: database ,         TF-IDF scores: 0.587 \n",
      "feature word: aleppo ,         TF-IDF scores: 0.531 \n",
      "feature word: observers ,         TF-IDF scores: 0.582 \n",
      "feature word: intellectual ,         TF-IDF scores: 0.515 \n",
      "feature word: maddow ,         TF-IDF scores: 0.511 \n",
      "feature word: egyptair ,         TF-IDF scores: 0.526 \n",
      "feature word: deaths ,         TF-IDF scores: 0.546 \n",
      "feature word: e-mails ,         TF-IDF scores: 0.551 \n",
      "feature word: waco ,         TF-IDF scores: 0.569 \n",
      "feature word: islamic ,         TF-IDF scores: 0.501 \n",
      "feature word: assange ,         TF-IDF scores: 0.553 \n",
      "feature word: virtual ,         TF-IDF scores: 0.54 \n",
      "feature word: scores ,         TF-IDF scores: 0.536 \n",
      "feature word: hanks ,         TF-IDF scores: 0.549 \n",
      "feature word: podesta ,         TF-IDF scores: 0.555 \n",
      "feature word: daesh ,         TF-IDF scores: 0.552 \n",
      "feature word: roadblock ,         TF-IDF scores: 0.551 \n",
      "feature word: x ,         TF-IDF scores: 0.527 \n",
      "feature word: raqqa ,         TF-IDF scores: 0.535 \n",
      "feature word: aleppo ,         TF-IDF scores: 0.589 \n",
      "feature word: pope ,         TF-IDF scores: 0.539 \n",
      "feature word: epa ,         TF-IDF scores: 0.542 \n",
      "feature word: scott ,         TF-IDF scores: 0.582 \n",
      "feature word: apologising ,         TF-IDF scores: 0.545 \n",
      "feature word: iran ,         TF-IDF scores: 0.523 \n",
      "feature word: russian ,         TF-IDF scores: 0.565 \n",
      "feature word: baba ,         TF-IDF scores: 0.589 \n",
      "feature word: prohibition ,         TF-IDF scores: 0.509 \n",
      "feature word: ttip ,         TF-IDF scores: 0.51 \n",
      "feature word: rumble ,         TF-IDF scores: 0.519 \n",
      "feature word: haley ,         TF-IDF scores: 0.571 \n",
      "feature word: mob ,         TF-IDF scores: 0.502 \n",
      "feature word: putin ,         TF-IDF scores: 0.508 \n",
      "feature word: satellite ,         TF-IDF scores: 0.595 \n",
      "feature word: ryan ,         TF-IDF scores: 0.596 \n",
      "feature word: braverman ,         TF-IDF scores: 0.596 \n",
      "feature word: crying ,         TF-IDF scores: 0.51 \n",
      "feature word: goat ,         TF-IDF scores: 0.528 \n",
      "feature word: drug ,         TF-IDF scores: 0.556 \n",
      "feature word: modi ,         TF-IDF scores: 0.524 \n",
      "feature word: unreal ,         TF-IDF scores: 0.581 \n",
      "feature word: catacombs ,         TF-IDF scores: 0.588 \n",
      "feature word: austyn ,         TF-IDF scores: 0.576 \n",
      "feature word: weeds ,         TF-IDF scores: 0.573 \n",
      "feature word: bush ,         TF-IDF scores: 0.513 \n",
      "feature word: school ,         TF-IDF scores: 0.579 \n",
      "feature word: black ,         TF-IDF scores: 0.586 \n",
      "feature word: marriage ,         TF-IDF scores: 0.539 \n",
      "feature word: warmest ,         TF-IDF scores: 0.552 \n",
      "feature word: winter ,         TF-IDF scores: 0.528 \n",
      "feature word: bush ,         TF-IDF scores: 0.576 \n",
      "feature word: bush ,         TF-IDF scores: 0.518 \n",
      "feature word: 16-year-old ,         TF-IDF scores: 0.525 \n",
      "feature word: pipeline ,         TF-IDF scores: 0.544 \n",
      "feature word: fiber ,         TF-IDF scores: 0.599 \n",
      "feature word: shootings ,         TF-IDF scores: 0.514 \n",
      "feature word: bush ,         TF-IDF scores: 0.539 \n",
      "feature word: winter ,         TF-IDF scores: 0.524 \n",
      "feature word: woolley ,         TF-IDF scores: 0.52 \n",
      "feature word: pussy ,         TF-IDF scores: 0.575 \n",
      "feature word: sanders ,         TF-IDF scores: 0.532 \n",
      "feature word: immigrants ,         TF-IDF scores: 0.551 \n",
      "feature word: delegates ,         TF-IDF scores: 0.553 \n",
      "feature word: bundy ,         TF-IDF scores: 0.514 \n",
      "feature word: vending ,         TF-IDF scores: 0.582 \n",
      "feature word: balfour ,         TF-IDF scores: 0.575 \n",
      "feature word: payment ,         TF-IDF scores: 0.517 \n",
      "feature word: rothschild ,         TF-IDF scores: 0.577 \n",
      "feature word: cruz ,         TF-IDF scores: 0.533 \n",
      "feature word: hodges ,         TF-IDF scores: 0.573 \n",
      "feature word: 650k ,         TF-IDF scores: 0.592 \n",
      "feature word: 126,000 ,         TF-IDF scores: 0.591 \n",
      "feature word: engulf ,         TF-IDF scores: 0.568 \n",
      "feature word: reopening ,         TF-IDF scores: 0.565 \n",
      "feature word: trump ,         TF-IDF scores: 0.519 \n",
      "feature word: kashmiriyat ,         TF-IDF scores: 0.531 \n",
      "feature word: machado ,         TF-IDF scores: 0.593 \n",
      "feature word: castro ,         TF-IDF scores: 0.585 \n",
      "feature word: farook ,         TF-IDF scores: 0.532 \n",
      "feature word: crowley ,         TF-IDF scores: 0.558 \n",
      "feature word: jews ,         TF-IDF scores: 0.527 \n",
      "feature word: arctic ,         TF-IDF scores: 0.514 \n",
      "feature word: shell ,         TF-IDF scores: 0.514 \n",
      "feature word: water ,         TF-IDF scores: 0.544 \n",
      "feature word: 1862 ,         TF-IDF scores: 0.548 \n",
      "feature word: runway ,         TF-IDF scores: 0.531 \n",
      "feature word: marriage ,         TF-IDF scores: 0.564 \n",
      "feature word: johnson ,         TF-IDF scores: 0.541 \n",
      "feature word: teachers ,         TF-IDF scores: 0.536 \n",
      "feature word: shame ,         TF-IDF scores: 0.534 \n",
      "feature word: cruz ,         TF-IDF scores: 0.526 \n",
      "feature word: blm ,         TF-IDF scores: 0.598 \n",
      "feature word: war ,         TF-IDF scores: 0.524 \n",
      "feature word: cuba ,         TF-IDF scores: 0.56 \n",
      "feature word: prerecorded ,         TF-IDF scores: 0.554 \n",
      "feature word: iran ,         TF-IDF scores: 0.568 \n",
      "feature word: comey ,         TF-IDF scores: 0.597 \n",
      "feature word: b ,         TF-IDF scores: 0.529 \n",
      "feature word: hatch ,         TF-IDF scores: 0.502 \n",
      "feature word: mormon ,         TF-IDF scores: 0.566 \n",
      "feature word: blvd… ,         TF-IDF scores: 0.575 \n",
      "feature word: hilary ,         TF-IDF scores: 0.504 \n",
      "feature word: blankets ,         TF-IDF scores: 0.512 \n",
      "feature word: tunisia ,         TF-IDF scores: 0.572 \n",
      "feature word: ghosts ,         TF-IDF scores: 0.509 \n",
      "feature word: border ,         TF-IDF scores: 0.575 \n",
      "feature word: pilger ,         TF-IDF scores: 0.571 \n",
      "feature word: baltimore ,         TF-IDF scores: 0.526 \n",
      "feature word: protesters ,         TF-IDF scores: 0.527 \n",
      "feature word: mccain ,         TF-IDF scores: 0.539 \n",
      "feature word: bush ,         TF-IDF scores: 0.535 \n",
      "feature word: pathological ,         TF-IDF scores: 0.565 \n",
      "feature word: syria ,         TF-IDF scores: 0.509 \n",
      "feature word: percent ,         TF-IDF scores: 0.526 \n",
      "feature word: 'anything ,         TF-IDF scores: 0.577 \n",
      "feature word: lewd ,         TF-IDF scores: 0.537 \n",
      "feature word: ice ,         TF-IDF scores: 0.532 \n",
      "feature word: nypd ,         TF-IDF scores: 0.551 \n",
      "feature word: delegates ,         TF-IDF scores: 0.586 \n",
      "feature word: kasich ,         TF-IDF scores: 0.598 \n",
      "feature word: ballot ,         TF-IDF scores: 0.578 \n",
      "feature word: globalist ,         TF-IDF scores: 0.52 \n",
      "feature word: ballots ,         TF-IDF scores: 0.521 \n",
      "feature word: postal ,         TF-IDF scores: 0.536 \n",
      "feature word: border ,         TF-IDF scores: 0.556 \n",
      "feature word: acquittal ,         TF-IDF scores: 0.541 \n",
      "feature word: sanders ,         TF-IDF scores: 0.524 \n",
      "feature word: johnson ,         TF-IDF scores: 0.502 \n",
      "feature word: imahdi ,         TF-IDF scores: 0.529 \n",
      "feature word: القادمون ,         TF-IDF scores: 0.529 \n",
      "feature word: shul ,         TF-IDF scores: 0.523 \n",
      "feature word: yemen ,         TF-IDF scores: 0.513 \n",
      "feature word: antarctica ,         TF-IDF scores: 0.551 \n",
      "feature word: • ,         TF-IDF scores: 0.552 \n",
      "feature word: wildlife ,         TF-IDF scores: 0.56 \n",
      "feature word: door ,         TF-IDF scores: 0.553 \n",
      "feature word: tax ,         TF-IDF scores: 0.527 \n",
      "feature word: delegates ,         TF-IDF scores: 0.519 \n",
      "feature word: iceland ,         TF-IDF scores: 0.589 \n",
      "feature word: urban ,         TF-IDF scores: 0.563 \n",
      "feature word: baby ,         TF-IDF scores: 0.515 \n",
      "feature word: eu ,         TF-IDF scores: 0.508 \n",
      "feature word: ryan ,         TF-IDF scores: 0.501 \n",
      "feature word: reprehensible ,         TF-IDF scores: 0.546 \n",
      "feature word: pledge ,         TF-IDF scores: 0.528 \n",
      "feature word: paris ,         TF-IDF scores: 0.511 \n",
      "feature word: pirate ,         TF-IDF scores: 0.564 \n",
      "feature word: un ,         TF-IDF scores: 0.529 \n",
      "feature word: litmus ,         TF-IDF scores: 0.578 \n",
      "feature word: editors ,         TF-IDF scores: 0.552 \n",
      "feature word: hedges ,         TF-IDF scores: 0.521 \n",
      "feature word: medea ,         TF-IDF scores: 0.53 \n",
      "feature word: shivaay ,         TF-IDF scores: 0.551 \n",
      "feature word: duma ,         TF-IDF scores: 0.543 \n",
      "feature word: tires ,         TF-IDF scores: 0.521 \n",
      "feature word: fires ,         TF-IDF scores: 0.583 \n",
      "feature word: churches ,         TF-IDF scores: 0.552 \n",
      "feature word: wallace ,         TF-IDF scores: 0.506 \n",
      "feature word: sequester ,         TF-IDF scores: 0.51 \n",
      "feature word: oliver ,         TF-IDF scores: 0.508 \n",
      "feature word: wasserman ,         TF-IDF scores: 0.52 \n",
      "feature word: iran ,         TF-IDF scores: 0.511 \n",
      "feature word: dnc ,         TF-IDF scores: 0.54 \n",
      "feature word: crazy ,         TF-IDF scores: 0.519 \n",
      "feature word: afghanistan ,         TF-IDF scores: 0.593 \n",
      "feature word: muhammad ,         TF-IDF scores: 0.545 \n",
      "feature word: russians ,         TF-IDF scores: 0.509 \n",
      "feature word: jets ,         TF-IDF scores: 0.521 \n",
      "feature word: millennials ,         TF-IDF scores: 0.51 \n",
      "feature word: reno ,         TF-IDF scores: 0.533 \n",
      "feature word: invader ,         TF-IDF scores: 0.577 \n",
      "feature word: iowa ,         TF-IDF scores: 0.531 \n",
      "feature word: bush ,         TF-IDF scores: 0.525 \n",
      "feature word: insist ,         TF-IDF scores: 0.511 \n",
      "feature word: signals ,         TF-IDF scores: 0.562 \n",
      "feature word: jobs ,         TF-IDF scores: 0.511 \n",
      "feature word: lap ,         TF-IDF scores: 0.573 \n",
      "feature word: college ,         TF-IDF scores: 0.597 \n",
      "feature word: dollar ,         TF-IDF scores: 0.537 \n",
      "feature word: mcconnell ,         TF-IDF scores: 0.536 \n",
      "feature word: costumes ,         TF-IDF scores: 0.518 \n",
      "feature word: afghan ,         TF-IDF scores: 0.503 \n",
      "feature word: soros ,         TF-IDF scores: 0.549 \n",
      "feature word: abedin ,         TF-IDF scores: 0.51 \n",
      "feature word: huma ,         TF-IDF scores: 0.506 \n",
      "feature word: dad ,         TF-IDF scores: 0.575 \n",
      "feature word: skousen ,         TF-IDF scores: 0.584 \n",
      "feature word: 275,000 ,         TF-IDF scores: 0.563 \n",
      "feature word: harvard ,         TF-IDF scores: 0.564 \n",
      "feature word: blacks ,         TF-IDF scores: 0.509 \n",
      "feature word: breakdown ,         TF-IDF scores: 0.574 \n",
      "feature word: communism ,         TF-IDF scores: 0.516 \n",
      "feature word: onpolitics ,         TF-IDF scores: 0.503 \n",
      "feature word: cabinet ,         TF-IDF scores: 0.562 \n",
      "feature word: lara ,         TF-IDF scores: 0.501 \n",
      "feature word: lights ,         TF-IDF scores: 0.57 \n",
      "feature word: jeptoo ,         TF-IDF scores: 0.519 \n",
      "feature word: wallace ,         TF-IDF scores: 0.531 \n",
      "feature word: davis ,         TF-IDF scores: 0.546 \n",
      "feature word: machado ,         TF-IDF scores: 0.511 \n",
      "feature word: cruz ,         TF-IDF scores: 0.562 \n",
      "feature word: mudry ,         TF-IDF scores: 0.531 \n",
      "feature word: yaroslav ,         TF-IDF scores: 0.531 \n",
      "feature word: endgame ,         TF-IDF scores: 0.582 \n",
      "feature word: cruz ,         TF-IDF scores: 0.578 \n",
      "feature word: milk ,         TF-IDF scores: 0.546 \n",
      "feature word: sanders ,         TF-IDF scores: 0.552 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.529 \n",
      "feature word: fbigate ,         TF-IDF scores: 0.516 \n",
      "feature word: sanders ,         TF-IDF scores: 0.523 \n",
      "feature word: williams ,         TF-IDF scores: 0.593 \n",
      "feature word: classified ,         TF-IDF scores: 0.554 \n",
      "feature word: globalization-v-localization ,         TF-IDF scores: 0.504 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.579 \n",
      "feature word: rubio ,         TF-IDF scores: 0.538 \n",
      "feature word: pap ,         TF-IDF scores: 0.516 \n",
      "feature word: backup ,         TF-IDF scores: 0.592 \n",
      "feature word: philadelphia ,         TF-IDF scores: 0.597 \n",
      "feature word: 117 ,         TF-IDF scores: 0.598 \n",
      "feature word: england ,         TF-IDF scores: 0.553 \n",
      "feature word: partisans ,         TF-IDF scores: 0.538 \n",
      "feature word: rappers ,         TF-IDF scores: 0.594 \n",
      "feature word: sermons ,         TF-IDF scores: 0.599 \n",
      "feature word: lakefront ,         TF-IDF scores: 0.52 \n",
      "feature word: epa ,         TF-IDF scores: 0.512 \n",
      "feature word: sanders ,         TF-IDF scores: 0.583 \n",
      "feature word: irs ,         TF-IDF scores: 0.599 \n",
      "feature word: sanders ,         TF-IDF scores: 0.516 \n",
      "feature word: aleppo ,         TF-IDF scores: 0.526 \n",
      "feature word: ali ,         TF-IDF scores: 0.514 \n",
      "feature word: hatch ,         TF-IDF scores: 0.571 \n",
      "feature word: campus ,         TF-IDF scores: 0.508 \n",
      "feature word: immigration ,         TF-IDF scores: 0.562 \n",
      "feature word: esquire ,         TF-IDF scores: 0.575 \n",
      "feature word: bundy ,         TF-IDF scores: 0.548 \n",
      "feature word: delegates ,         TF-IDF scores: 0.581 \n",
      "feature word: police ,         TF-IDF scores: 0.506 \n",
      "feature word: correctness ,         TF-IDF scores: 0.541 \n",
      "feature word: schultz ,         TF-IDF scores: 0.577 \n",
      "feature word: wasserman ,         TF-IDF scores: 0.57 \n",
      "feature word: data ,         TF-IDF scores: 0.539 \n",
      "feature word: move ,         TF-IDF scores: 0.587 \n",
      "feature word: guest ,         TF-IDF scores: 0.522 \n",
      "feature word: marriage ,         TF-IDF scores: 0.56 \n",
      "feature word: emails ,         TF-IDF scores: 0.531 \n",
      "feature word: kaliningrad ,         TF-IDF scores: 0.552 \n",
      "feature word: quarter ,         TF-IDF scores: 0.504 \n",
      "feature word: harf ,         TF-IDF scores: 0.536 \n",
      "feature word: aleppo ,         TF-IDF scores: 0.509 \n",
      "feature word: chlorine ,         TF-IDF scores: 0.519 \n",
      "feature word: cruz ,         TF-IDF scores: 0.503 \n",
      "feature word: sirte ,         TF-IDF scores: 0.521 \n",
      "feature word: bee ,         TF-IDF scores: 0.504 \n",
      "feature word: torch ,         TF-IDF scores: 0.52 \n",
      "feature word: teachers ,         TF-IDF scores: 0.529 \n",
      "feature word: huckabee ,         TF-IDF scores: 0.52 \n",
      "feature word: sweden ,         TF-IDF scores: 0.514 \n",
      "feature word: 9/11 ,         TF-IDF scores: 0.546 \n",
      "feature word: delegates ,         TF-IDF scores: 0.571 \n",
      "feature word: profit ,         TF-IDF scores: 0.59 \n",
      "feature word: rules ,         TF-IDF scores: 0.586 \n",
      "feature word: water ,         TF-IDF scores: 0.59 \n",
      "feature word: bibi ,         TF-IDF scores: 0.562 \n",
      "feature word: kaine ,         TF-IDF scores: 0.528 \n",
      "feature word: stone ,         TF-IDF scores: 0.567 \n",
      "feature word: electoral ,         TF-IDF scores: 0.514 \n",
      "feature word: coulter ,         TF-IDF scores: 0.596 \n",
      "feature word: boehner ,         TF-IDF scores: 0.525 \n",
      "feature word: schumer ,         TF-IDF scores: 0.59 \n",
      "feature word: creamer ,         TF-IDF scores: 0.549 \n",
      "feature word: geomagnetic ,         TF-IDF scores: 0.597 \n",
      "feature word: iran ,         TF-IDF scores: 0.553 \n",
      "feature word: authorization ,         TF-IDF scores: 0.501 \n",
      "feature word: cuba ,         TF-IDF scores: 0.517 \n",
      "feature word: fox ,         TF-IDF scores: 0.546 \n",
      "feature word: facial ,         TF-IDF scores: 0.501 \n",
      "feature word: davis ,         TF-IDF scores: 0.537 \n",
      "feature word: licenses ,         TF-IDF scores: 0.543 \n",
      "feature word: fec ,         TF-IDF scores: 0.591 \n",
      "feature word: yale ,         TF-IDF scores: 0.553 \n",
      "feature word: assange ,         TF-IDF scores: 0.571 \n",
      "feature word: evangelicals ,         TF-IDF scores: 0.501 \n",
      "feature word: un ,         TF-IDF scores: 0.523 \n",
      "feature word: boehner ,         TF-IDF scores: 0.529 \n",
      "feature word: santorum ,         TF-IDF scores: 0.545 \n",
      "feature word: rebels ,         TF-IDF scores: 0.507 \n",
      "feature word: supposedly ,         TF-IDF scores: 0.523 \n",
      "feature word: 207 ,         TF-IDF scores: 0.506 \n",
      "feature word: fbi ,         TF-IDF scores: 0.587 \n",
      "feature word: solar ,         TF-IDF scores: 0.505 \n",
      "feature word: magic ,         TF-IDF scores: 0.595 \n",
      "feature word: parenthood ,         TF-IDF scores: 0.508 \n",
      "feature word: solar ,         TF-IDF scores: 0.576 \n",
      "feature word: capitol ,         TF-IDF scores: 0.573 \n",
      "feature word: fukushima ,         TF-IDF scores: 0.59 \n",
      "feature word: drone ,         TF-IDF scores: 0.512 \n",
      "feature word: gold ,         TF-IDF scores: 0.549 \n",
      "feature word: colombia ,         TF-IDF scores: 0.578 \n",
      "feature word: montenegro ,         TF-IDF scores: 0.573 \n",
      "feature word: autism ,         TF-IDF scores: 0.563 \n",
      "feature word: dnc ,         TF-IDF scores: 0.57 \n",
      "feature word: subsidies ,         TF-IDF scores: 0.514 \n",
      "feature word: adhd ,         TF-IDF scores: 0.506 \n",
      "feature word: aumf ,         TF-IDF scores: 0.556 \n",
      "feature word: bad-tempered ,         TF-IDF scores: 0.501 \n",
      "feature word: roll ,         TF-IDF scores: 0.528 \n",
      "feature word: jews ,         TF-IDF scores: 0.564 \n",
      "feature word: guns ,         TF-IDF scores: 0.509 \n",
      "feature word: robots ,         TF-IDF scores: 0.532 \n",
      "feature word: automation ,         TF-IDF scores: 0.583 \n",
      "feature word: pardon ,         TF-IDF scores: 0.511 \n",
      "feature word: obamamometer ,         TF-IDF scores: 0.57 \n",
      "feature word: cruz ,         TF-IDF scores: 0.534 \n",
      "feature word: moon ,         TF-IDF scores: 0.553 \n",
      "feature word: pa ,         TF-IDF scores: 0.538 \n",
      "feature word: sanders ,         TF-IDF scores: 0.53 \n",
      "feature word: tests ,         TF-IDF scores: 0.518 \n",
      "feature word: parenthood ,         TF-IDF scores: 0.538 \n",
      "feature word: abortion ,         TF-IDF scores: 0.501 \n",
      "feature word: nepal ,         TF-IDF scores: 0.594 \n",
      "feature word: pre-campaign ,         TF-IDF scores: 0.525 \n",
      "feature word: voyager ,         TF-IDF scores: 0.515 \n",
      "feature word: lance ,         TF-IDF scores: 0.531 \n",
      "feature word: bush ,         TF-IDF scores: 0.547 \n",
      "feature word: fox ,         TF-IDF scores: 0.577 \n",
      "feature word: wendy ,         TF-IDF scores: 0.564 \n",
      "feature word: correctness ,         TF-IDF scores: 0.552 \n",
      "feature word: migrant ,         TF-IDF scores: 0.569 \n",
      "feature word: iran ,         TF-IDF scores: 0.588 \n",
      "feature word: art ,         TF-IDF scores: 0.549 \n",
      "feature word: egg ,         TF-IDF scores: 0.542 \n",
      "feature word: easter ,         TF-IDF scores: 0.544 \n",
      "feature word: kirkuk ,         TF-IDF scores: 0.576 \n",
      "feature word: approval ,         TF-IDF scores: 0.576 \n",
      "feature word: birds ,         TF-IDF scores: 0.57 \n",
      "feature word: goldman ,         TF-IDF scores: 0.552 \n",
      "feature word: juicing ,         TF-IDF scores: 0.597 \n",
      "feature word: quietly ,         TF-IDF scores: 0.539 \n",
      "feature word: ufo ,         TF-IDF scores: 0.504 \n",
      "feature word: mcconnell ,         TF-IDF scores: 0.554 \n",
      "feature word: films ,         TF-IDF scores: 0.593 \n",
      "feature word: shiny ,         TF-IDF scores: 0.521 \n",
      "feature word: paul ,         TF-IDF scores: 0.552 \n",
      "feature word: yemen ,         TF-IDF scores: 0.542 \n",
      "feature word: hill ,         TF-IDF scores: 0.55 \n",
      "feature word: polarization ,         TF-IDF scores: 0.55 \n",
      "feature word: bush ,         TF-IDF scores: 0.558 \n",
      "feature word: facebook ,         TF-IDF scores: 0.597 \n",
      "feature word: gillibrand ,         TF-IDF scores: 0.522 \n",
      "feature word: doe ,         TF-IDF scores: 0.564 \n",
      "feature word: lil ,         TF-IDF scores: 0.558 \n",
      "feature word: marriage ,         TF-IDF scores: 0.561 \n",
      "feature word: globalism ,         TF-IDF scores: 0.529 \n",
      "feature word: wont ,         TF-IDF scores: 0.556 \n",
      "feature word: mlk ,         TF-IDF scores: 0.504 \n",
      "feature word: invokes ,         TF-IDF scores: 0.504 \n",
      "feature word: manafort ,         TF-IDF scores: 0.515 \n",
      "feature word: loves ,         TF-IDF scores: 0.559 \n",
      "feature word: tunisia ,         TF-IDF scores: 0.595 \n",
      "feature word: weekend ,         TF-IDF scores: 0.515 \n",
      "feature word: wireless ,         TF-IDF scores: 0.582 \n",
      "feature word: weiner ,         TF-IDF scores: 0.547 \n",
      "feature word: huma ,         TF-IDF scores: 0.55 \n",
      "feature word: ursula ,         TF-IDF scores: 0.536 \n",
      "feature word: kilograms ,         TF-IDF scores: 0.546 \n",
      "feature word: gulf ,         TF-IDF scores: 0.565 \n",
      "feature word: diy ,         TF-IDF scores: 0.501 \n",
      "feature word: stars ,         TF-IDF scores: 0.552 \n",
      "feature word: clown ,         TF-IDF scores: 0.564 \n",
      "feature word: drivers ,         TF-IDF scores: 0.553 \n",
      "feature word: 2:00pm ,         TF-IDF scores: 0.56 \n",
      "feature word: moms ,         TF-IDF scores: 0.551 \n",
      "feature word: sanders ,         TF-IDF scores: 0.564 \n",
      "feature word: clawbacks ,         TF-IDF scores: 0.519 \n",
      "feature word: black ,         TF-IDF scores: 0.561 \n",
      "feature word: boehner ,         TF-IDF scores: 0.516 \n",
      "feature word: creamer ,         TF-IDF scores: 0.517 \n",
      "feature word: hadi ,         TF-IDF scores: 0.572 \n",
      "feature word: musou ,         TF-IDF scores: 0.543 \n",
      "feature word: bus ,         TF-IDF scores: 0.535 \n",
      "feature word: rating ,         TF-IDF scores: 0.526 \n",
      "feature word: rebel ,         TF-IDF scores: 0.52 \n",
      "feature word: veritas ,         TF-IDF scores: 0.572 \n",
      "feature word: mikulski ,         TF-IDF scores: 0.554 \n",
      "feature word: apple ,         TF-IDF scores: 0.507 \n",
      "feature word: capstone ,         TF-IDF scores: 0.585 \n",
      "feature word: pyramid ,         TF-IDF scores: 0.59 \n",
      "feature word: rubio ,         TF-IDF scores: 0.505 \n",
      "feature word: redskins ,         TF-IDF scores: 0.522 \n",
      "feature word: secrecy ,         TF-IDF scores: 0.518 \n",
      "feature word: hilary ,         TF-IDF scores: 0.587 \n",
      "feature word: 6-point ,         TF-IDF scores: 0.537 \n",
      "feature word: trunews ,         TF-IDF scores: 0.583 \n",
      "feature word: consciousness ,         TF-IDF scores: 0.533 \n",
      "feature word: 1 ,         TF-IDF scores: 0.514 \n",
      "feature word: afghan ,         TF-IDF scores: 0.558 \n",
      "feature word: raqqa ,         TF-IDF scores: 0.566 \n",
      "feature word: obamacare ,         TF-IDF scores: 0.507 \n",
      "feature word: wall ,         TF-IDF scores: 0.571 \n",
      "feature word: google ,         TF-IDF scores: 0.598 \n",
      "feature word: isis ,         TF-IDF scores: 0.573 \n",
      "feature word: cpac ,         TF-IDF scores: 0.534 \n",
      "feature word: hes ,         TF-IDF scores: 0.515 \n",
      "feature word: transition ,         TF-IDF scores: 0.553 \n",
      "feature word: johnson ,         TF-IDF scores: 0.587 \n",
      "feature word: stein ,         TF-IDF scores: 0.506 \n",
      "feature word: brexit ,         TF-IDF scores: 0.523 \n",
      "feature word: feelthechafe ,         TF-IDF scores: 0.518 \n",
      "feature word: warhead ,         TF-IDF scores: 0.529 \n",
      "feature word: lobby ,         TF-IDF scores: 0.519 \n",
      "feature word: god ,         TF-IDF scores: 0.503 \n",
      "feature word: colin ,         TF-IDF scores: 0.564 \n",
      "feature word: rubio ,         TF-IDF scores: 0.549 \n",
      "feature word: screen ,         TF-IDF scores: 0.532 \n",
      "feature word: kit ,         TF-IDF scores: 0.524 \n",
      "feature word: cruz ,         TF-IDF scores: 0.555 \n",
      "feature word: malaysia ,         TF-IDF scores: 0.523 \n",
      "feature word: nasa ,         TF-IDF scores: 0.579 \n",
      "feature word: feminazis ,         TF-IDF scores: 0.592 \n",
      "feature word: percent ,         TF-IDF scores: 0.549 \n",
      "feature word: parenthood ,         TF-IDF scores: 0.563 \n",
      "feature word: foval ,         TF-IDF scores: 0.514 \n",
      "feature word: coming-out ,         TF-IDF scores: 0.598 \n",
      "feature word: mcconnell ,         TF-IDF scores: 0.533 \n",
      "feature word: percent ,         TF-IDF scores: 0.571 \n",
      "feature word: carson ,         TF-IDF scores: 0.596 \n",
      "feature word: oil ,         TF-IDF scores: 0.57 \n",
      "feature word: cabal ,         TF-IDF scores: 0.518 \n",
      "feature word: gold ,         TF-IDF scores: 0.574 \n",
      "feature word: netanyahu ,         TF-IDF scores: 0.505 \n",
      "feature word: cuba ,         TF-IDF scores: 0.587 \n",
      "feature word: comey ,         TF-IDF scores: 0.575 \n",
      "feature word: facial ,         TF-IDF scores: 0.546 \n",
      "feature word: canadian ,         TF-IDF scores: 0.597 \n",
      "feature word: johnson ,         TF-IDF scores: 0.584 \n",
      "feature word: creamer ,         TF-IDF scores: 0.567 \n",
      "feature word: duggars ,         TF-IDF scores: 0.561 \n",
      "feature word: norwegian ,         TF-IDF scores: 0.583 \n",
      "feature word: drone ,         TF-IDF scores: 0.536 \n",
      "feature word: breakfast ,         TF-IDF scores: 0.526 \n",
      "feature word: hurtling ,         TF-IDF scores: 0.563 \n",
      "feature word: cruz ,         TF-IDF scores: 0.502 \n",
      "feature word: exchanges ,         TF-IDF scores: 0.522 \n",
      "feature word: kelly ,         TF-IDF scores: 0.515 \n",
      "feature word: bird ,         TF-IDF scores: 0.534 \n",
      "feature word: predator ,         TF-IDF scores: 0.511 \n",
      "feature word: advertisers ,         TF-IDF scores: 0.584 \n",
      "feature word: yugoslavia ,         TF-IDF scores: 0.527 \n",
      "feature word: reid ,         TF-IDF scores: 0.585 \n",
      "feature word: star ,         TF-IDF scores: 0.521 \n",
      "feature word: astronomers ,         TF-IDF scores: 0.526 \n",
      "feature word: blair ,         TF-IDF scores: 0.542 \n",
      "feature word: missile ,         TF-IDF scores: 0.568 \n",
      "feature word: baier ,         TF-IDF scores: 0.507 \n",
      "feature word: smells ,         TF-IDF scores: 0.557 \n",
      "feature word: flags ,         TF-IDF scores: 0.524 \n",
      "feature word: korea ,         TF-IDF scores: 0.585 \n",
      "feature word: amp ,         TF-IDF scores: 0.578 \n",
      "feature word: ryan ,         TF-IDF scores: 0.51 \n",
      "feature word: bristle ,         TF-IDF scores: 0.585 \n",
      "feature word: moby ,         TF-IDF scores: 0.583 \n",
      "feature word: contrarian ,         TF-IDF scores: 0.587 \n",
      "feature word: assange ,         TF-IDF scores: 0.591 \n",
      "feature word: semen ,         TF-IDF scores: 0.588 \n",
      "feature word: hiv ,         TF-IDF scores: 0.576 \n",
      "feature word: davis ,         TF-IDF scores: 0.578 \n",
      "feature word: conway ,         TF-IDF scores: 0.573 \n",
      "feature word: iran ,         TF-IDF scores: 0.534 \n",
      "feature word: 10k ,         TF-IDF scores: 0.516 \n",
      "feature word: muslim ,         TF-IDF scores: 0.547 \n",
      "feature word: carson ,         TF-IDF scores: 0.503 \n",
      "feature word: prepping ,         TF-IDF scores: 0.538 \n",
      "feature word: embargo ,         TF-IDF scores: 0.516 \n",
      "feature word: cruz ,         TF-IDF scores: 0.554 \n",
      "feature word: sanders ,         TF-IDF scores: 0.577 \n",
      "feature word: bush ,         TF-IDF scores: 0.586 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(w_tfidf)):\n",
    "    print('feature word: {} ,         TF-IDF scores: {} '.format(feature_importance[i],w_tfidf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> (6335, 1389)\n"
     ]
    }
   ],
   "source": [
    "feature_text = np.zeros((texts.shape[0], len(feature_importance)))\n",
    "print(type(feature_importance),feature_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "text= {}\n",
    "index=0\n",
    "for word in feature_importance:\n",
    "    text[word] = index\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 1389)\n"
     ]
    }
   ],
   "source": [
    "for i in range(texts.shape[0]):\n",
    "   # for j in tfidf[corpus[i]]:\n",
    "        for word in c_title[i]:\n",
    "            if word in feature_importance:\n",
    "                feature_text[i, text[word]] +=1\n",
    "print(feature_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_vec = pd.DataFrame(feature_text)\n",
    "x_0 = pd.concat([feature_vec], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4433,)\n",
      "(951,)\n",
      "(951,)\n"
     ]
    }
   ],
   "source": [
    "#forming training sets and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = np.asarray(df['label'])\n",
    "seed = 42\n",
    "test_size = 0.15 #\n",
    "validation_size = 0.15/(1-test_size)\n",
    "\n",
    "x0_train, x0_test, y0_train, y0_test = train_test_split(x_0, y, test_size=test_size, random_state=seed)\n",
    "x0_train, x0_validation, y0_train, y0_validation = train_test_split(x0_train, y0_train, test_size=validation_size, random_state=seed)\n",
    "print(y0_train.shape)\n",
    "print(y0_test.shape)\n",
    "print(y0_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.81      0.68      0.74       492\n",
      "       real       0.71      0.82      0.76       459\n",
      "\n",
      "avg / total       0.76      0.75      0.75       951\n",
      "\n",
      "0.750788643533123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model0 = LogisticRegression()\n",
    "model0 = model.fit(x0_train, y0_train)\n",
    "\n",
    "y0_pred = model.predict(x0_test)\n",
    "print(\"LR:\")\n",
    "print(classification_report(y0_test, y0_pred, target_names=target_names))\n",
    "print(model0.score(x0_test, y0_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 300) (6335, 1389)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,feature_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 1689)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.hstack((x, feature_text))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4433,)\n",
      "(951,)\n",
      "(951,)\n"
     ]
    }
   ],
   "source": [
    "#forming training sets and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = np.asarray(df['label'])\n",
    "seed = 42\n",
    "test_size = 0.15 #\n",
    "validation_size = 0.15/(1-test_size)\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(A, y, test_size=test_size, random_state=seed)\n",
    "x1_train, x1_validation, y1_train, y1_validation = train_test_split(x1_train, y1_train, test_size=validation_size, random_state=seed)\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)\n",
    "print(y1_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.94      0.94      0.94       492\n",
      "       real       0.93      0.93      0.93       459\n",
      "\n",
      "avg / total       0.93      0.93      0.93       951\n",
      "\n",
      "0.9348054679284963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1 = model.fit(x1_train, y1_train)\n",
    "\n",
    "y1_pred = model.predict(x1_test)\n",
    "print(\"LR:\")\n",
    "print(classification_report(y1_test, y1_pred, target_names=target_names))\n",
    "print(model0.score(x1_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.93      0.91      0.92       492\n",
      "       real       0.91      0.92      0.91       459\n",
      "\n",
      "avg / total       0.92      0.92      0.92       951\n",
      "\n",
      "0.9169295478443743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "target_names = ['fake', 'real']\n",
    "\n",
    "svc.fit(x1_train, y1_train)\n",
    "\n",
    "y_2pred = svc.predict(x1_test)\n",
    "print(\"SVM:\")\n",
    "print(classification_report(y1_test, y_2pred, target_names=target_names))\n",
    "print(svc.score(x1_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.94      0.94      0.94       492\n",
      "       real       0.93      0.94      0.94       459\n",
      "\n",
      "avg / total       0.94      0.94      0.94       951\n",
      "\n",
      "0.9390115667718192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.0,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.0005,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "xgb2.fit(x1_train, y1_train)\n",
    "y1_pred = xgb2.predict(x1_test)\n",
    "\n",
    "target_names = ['fake', 'real']\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y1_test, y1_pred, target_names=target_names))\n",
    "print(xgb2.score(x1_test, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method2: doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "class TagDocIterator:\n",
    "    def __init__(self, doc_list, idx_list):\n",
    "        self.doc_list = doc_list\n",
    "        self.idx_list = idx_list\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for doc, idx, in zip(self.doc_list, self.idx_list):\n",
    "            tag = [idx]\n",
    "            yield TaggedDocument(words=doc, tags=tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doc2Vec Parameters\n",
    "\n",
    "- `dm` (distributed memory): '0' indicates DBOW model; '1' indicates DM\n",
    "- `size`: Number of dimensions for the embedding model\n",
    "- `window`: Number of context words to observe in each direction within a document\n",
    "- `min_count`: Minimum frequency for words included in model\n",
    "- `mean`: if 0 (default), use the sum of the context word vectors. If 1, use the mean. Only applies when dm is used in non-concatenative mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d2v_params():\n",
    "    params = {\n",
    "        'dm': (0, 1),\n",
    "        'size': (100, 150, 300),\n",
    "        'window': (3, 5, 8, 10, 15),\n",
    "        'mean': (0, 1),\n",
    "        'min_count': (5, 10, 20, 30), \n",
    "    }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create and train the doc2vec model by changing its \n",
    "def d2v_fit(dm,size,window,mean,min_count):\n",
    "  doc2vec = Doc2Vec(size=size, \n",
    "                    window=window,\n",
    "                    min_count=min_count,\n",
    "                    dm = dm,\n",
    "                    mean=mean,\n",
    "                    alpha = 0.05,\n",
    "                    iter=10)\n",
    "  # Build the word2vec model from the corpus\n",
    "  doc2vec.build_vocab(TagDocIterator(c_extend, df.index))\n",
    "  doc2vec.train(TagDocIterator(c_extend, df.index), epochs = 5, total_examples = doc2vec.corpus_count)\n",
    "  return doc2vec.docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:355: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm: 0 , size: 100 , window: 3 , mean: 0 , min_count: 5 , accuracy: 0.9273875295974744\n",
      "dm: 0 , size: 100 , window: 3 , mean: 1 , min_count: 5 , accuracy: 0.9313338595106551\n",
      "dm: 0 , size: 100 , window: 5 , mean: 0 , min_count: 10 , accuracy: 0.9329123914759274\n",
      "dm: 0 , size: 100 , window: 5 , mean: 1 , min_count: 30 , accuracy: 0.9344909234411997\n",
      "dm: 0 , size: 300 , window: 8 , mean: 1 , min_count: 10 , accuracy: 0.936069455406472\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "y = np.asarray(df['label'])\n",
    "seed = 42\n",
    "test_size = 0.2\n",
    "best_ac=0.0\n",
    "b_dm=[]\n",
    "b_size=[]\n",
    "b_window=[]\n",
    "b_mean=[]\n",
    "b_min_count=[]\n",
    "for dm,size,window,mean,min_count in product( d2v_params()['dm'],d2v_params()['size'], d2v_params()['window'], d2v_params()['mean'],d2v_params()['min_count']):\n",
    "        docvecs = d2v_fit(dm,size,window,mean,min_count)\n",
    "        x = np.empty([df.shape[0],size])\n",
    "        for i in range(df.shape[0]):\n",
    "            x[i] = docvecs[i]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=seed)\n",
    "        model = LogisticRegression()\n",
    "        model = model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy= model.score(x_test, y_test)\n",
    "        if best_ac < accuracy:\n",
    "            best_ac=accuracy\n",
    "            b_dm=dm\n",
    "            b_size=size\n",
    "            b_window=window\n",
    "            b_mean=mean\n",
    "            b_min_count=min_count\n",
    "            print('dm: {} , size: {} , window: {} , mean: {} , min_count: {} , accuracy: {}'.format(b_dm,b_size,b_window,b_mean,b_min_count, best_ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:355: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "docvecs = d2v_fit(0,300,8,1,10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.empty([df.shape[0],300])\n",
    "for i in range(df.shape[0]):\n",
    "            x[i] = docvecs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: train, test, validation set split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ratio of spliting:\n",
    "\n",
    "train : validation : test = 8 : 1 : 1\n",
    "\n",
    "                            7 : 1.5: 1.5\n",
    "\n",
    "                            7 : 1 : 2\n",
    "                            \n",
    "                            7 : 2 : 1\n",
    "                            \n",
    "                            6 : 2 : 2\n",
    "                            \n",
    "                            5 : 2.5: 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4433,)\n",
      "(951,)\n",
      "(951,)\n"
     ]
    }
   ],
   "source": [
    "#forming training sets and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = np.asarray(df['label'])\n",
    "seed = 42\n",
    "test_size = 0.15 #\n",
    "validation_size = 0.15/(1-test_size)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=seed)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=validation_size, random_state=seed)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337539432176656"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model = model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result：                                       accuracy                                  \n",
    "\n",
    "train : validation : test =                  \n",
    "                            \n",
    "                            8 : 1 : 1        0.9290220820189274\n",
    "                \n",
    "                            7 : 1.5 : 1.5    0.9337539432176656\n",
    "                            \n",
    "                            7 : 1 : 2        0.930544593528019\n",
    "                                    \n",
    "                            7 : 2 : 1        0.9290220820189274 \n",
    "                                    \n",
    "                            6 : 2 : 2        0.9297553275453828\n",
    "                                    \n",
    "                            5 : 2.5: 2.5     0.9248737373737373\n",
    "so we decided to take 7:1.5:1.5 as our ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5: Try different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the different models here and see how it preforms on the validation set\n",
    "\n",
    "*** models includes:\n",
    "\n",
    "1:logistic regression\n",
    "\n",
    "2:SVM\n",
    "\n",
    "3:XGBoost\n",
    "\n",
    "4:random forest\n",
    "\n",
    "5:Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model = model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.92      0.93      0.93       454\n",
      "       real       0.94      0.93      0.93       497\n",
      "\n",
      "avg / total       0.93      0.93      0.93       951\n",
      "\n",
      "0.9305993690851735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['fake', 'real']\n",
    "print('logistic regression:')\n",
    "print(classification_report(y_validation, y_pred, target_names=target_names))\n",
    "print(model.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2:SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.92      0.93      0.93       454\n",
      "       real       0.94      0.93      0.93       497\n",
      "\n",
      "avg / total       0.93      0.93      0.93       951\n",
      "\n",
      "0.9284963196635121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "target_names = ['fake', 'real']\n",
    "\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(x_validation)\n",
    "print(\"SVM:\")\n",
    "print(classification_report(y_validation, y_pred, target_names=target_names))\n",
    "print(svc.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3:XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used: 45.55409682051322  s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "start_xgb = time.clock()\n",
    "\n",
    "XGmodel = XGBClassifier(max_depth=8, learning_rate=0.8, \n",
    "                        n_estimators=1000, silent=True, \n",
    "                        objective='binary:logistic', nthread=-1, \n",
    "                        gamma=0, min_child_weight=1, max_delta_step=0, \n",
    "                        subsample=1, colsample_bytree=1, \n",
    "                        colsample_bylevel=1, reg_alpha=0, \n",
    "                        reg_lambda=1, scale_pos_weight=0.9, \n",
    "                        base_score=0.6, seed=50, missing=None)\n",
    "\n",
    "XGmodel.fit(x_train, y_train)\n",
    "\n",
    "elapsed_xgb = (time.clock() - start_xgb)\n",
    "\n",
    "print(\"Time used:\",elapsed_xgb,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.92      0.94      0.93       454\n",
      "       real       0.95      0.93      0.94       497\n",
      "\n",
      "avg / total       0.94      0.94      0.94       951\n",
      "\n",
      "0.935856992639327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_vpred = XGmodel.predict(x_validation)\n",
    "\n",
    "target_names = ['fake', 'real']\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_validation, y_vpred, target_names=target_names))\n",
    "print(XGmodel.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4:Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 20, max_features=100, random_state=seed)\n",
    "RF_model = RF_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.88      0.91      0.90       454\n",
      "       real       0.92      0.89      0.90       497\n",
      "\n",
      "avg / total       0.90      0.90      0.90       951\n",
      "\n",
      "0.9011566771819137\n"
     ]
    }
   ],
   "source": [
    "y_vpred_rf = RF_model.predict(x_validation)\n",
    "target_names = ['fake', 'real']\n",
    "print('random forest:')\n",
    "print(classification_report(y_validation, y_vpred_rf, target_names=target_names))\n",
    "print(RF_model.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5：multilayer perceptron neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'alpha': 0.005,\n",
    "    'hidden_layer_sizes': (500, 800)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlp.set_params(**params)\n",
    "mlp.fit(x_train, y_train)\n",
    "y_pred_mlp = mlp.predict(x_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target_names = ['fake', 'real']\n",
    "print('random forest:')\n",
    "print(classification_report(y_validation, y_pred_mlp, target_names=target_names))\n",
    "print(mlp.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion of this part:\n",
    "\n",
    "- `logistic regression`: simple binary clasiifier, we use this classifier to do a lot of hypertuning on doc2vec and ratio of train, test,validation split\n",
    "- `svm`: socre:0.928, Support Vector Machines is good at linear binary question so we don't descuss here.\n",
    "- `XGBoost`: score:0.936, the best result we got so far, so we decided to focus on this model and carefully do hypertuning on this model.\n",
    "- `Random forest`: score:0.901, the score is the worse because we just set two parameters in our model, which is estimator and max_feature, and this two paramters is set by our intuition, we haven't did hypertuning yet.\n",
    "- `Neural network`: score:0.918, it's not that good because we need more information to train our neural network, but in our case, the data is still not that large  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6: hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:hypertuning on Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest parameters neeeds to be tuned:\n",
    "\n",
    "(1)max_features\n",
    "- The number of features to consider while searching for a best split. These will be randomly selected.\n",
    "- As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    "- Higher values can lead to over-fitting but depends on case to case.\n",
    "\n",
    "(2)max_depth\n",
    "- The maximum depth of a tree.\n",
    "- Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "- Should be tuned using CV.\n",
    "\n",
    "(3)min_samples_leaf\n",
    "- Defines the minimum samples (or observations) required in a terminal node or leaf.\n",
    "- Used to control over-fitting similar to min_samples_split.\n",
    "- Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.\n",
    "\n",
    "(4)min_samples_split\n",
    "- Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "- Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "- Too high values can lead to under-fitting hence, it should be tuned using CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tree-infographic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 63.60 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.901 (std: 0.003)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 7, 'max_features': 82, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.863 (std: 0.007)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 86, 'min_samples_leaf': 7, 'min_samples_split': 9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.899 (std: 0.009)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 7, 'max_features': 90, 'min_samples_leaf': 4, 'min_samples_split': 7}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.859 (std: 0.003)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 81, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.889 (std: 0.003)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 5, 'max_features': 74, 'min_samples_leaf': 9, 'min_samples_split': 7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# build a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=5):\n",
    "    # sort scores based on metric so we can grab the n_top models\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    # iterate over the n_top models\n",
    "    for i in range(n_top):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              grid_scores['mean_test_score'][i],\n",
    "              grid_scores['std_test_score'][i]))\n",
    "        print(\"Parameters: {0}\".format(grid_scores['params'][i]))\n",
    "        print(\"\")        \n",
    "param_dist = {\"max_depth\": [3, 5, 7],\n",
    "              \"max_features\": sp_randint(1, 100),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "# number of models we are going to train\n",
    "n_iter_search = 20\n",
    "# create our randomized gridsearch classifier\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,n_jobs=-1, return_train_score=True)\n",
    "# start a timer so we know how long the random gridsearch took\n",
    "start = time()\n",
    "# perform the random gridsearch\n",
    "random_search.fit(x, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "# print the top 3 model outputs from the random gridsearch\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed=42\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 20, max_depth=7,max_features=82, min_samples_leaf= 2, min_samples_split= 5,random_state=seed)\n",
    "RF_model = RF_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.91      0.92      0.92       492\n",
      "       real       0.92      0.90      0.91       459\n",
      "\n",
      "avg / total       0.91      0.91      0.91       951\n",
      "\n",
      "0.9148264984227129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_rf = RF_model.predict(x_test)\n",
    "target_names = ['fake', 'real']\n",
    "print('random forest:')\n",
    "print(classification_report(y_test, y_pred_rf, target_names=target_names))\n",
    "print(RF_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2:hypertuning on XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The XGBoost Advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1)Regularization:\n",
    "\n",
    "Standard GBM implementation has no regularization like XGBoost, therefore it also helps to reduce overfitting.\n",
    "In fact, XGBoost is also known as ‘regularized boosting‘ technique.\n",
    "\n",
    "(2)Parallel Processing:\n",
    "\n",
    "XGBoost implements parallel processing and is blazingly faster as compared to GBM.\n",
    "But hang on, we know that boosting is sequential process so how can it be parallelized? We know that each tree can be built only after the previous one, so what stops us from making a tree using all cores? I hope you get where I’m coming from. Check this link out to explore further.\n",
    "XGBoost also supports implementation on Hadoop.\n",
    "\n",
    "(3)High Flexibility:\n",
    "\n",
    "XGBoost allow users to define custom optimization objectives and evaluation criteria.\n",
    "This adds a whole new dimension to the model and there is no limit to what we can do.\n",
    "\n",
    "(4)Continue on Existing Model:\n",
    "\n",
    "User can start training an XGBoost model from its last iteration of previous run. This can be of significant advantage in certain specific applications.\n",
    "GBM implementation of sklearn also has this feature so they are even on this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall parameters have been divided into 3 categories by XGBoost authors:\n",
    "1. General Parameters: Guide the overall functioning\n",
    "2. Booster Parameters: Guide the individual booster (tree/regression) at each step\n",
    "3. Learning Task Parameters: Guide the optimization performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General Parameters\n",
    "These define the overall functionality of XGBoost:\n",
    "1. booster [default=gbtree]\n",
    "2. silent [default=0]\n",
    "3. nthread [default to maximum number of threads available if not set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Booster Parameters\n",
    "Though there are 2 types of boosters, I’ll consider only tree booster here because it always outperforms the linear booster and thus the later is rarely used.\n",
    "1. eta [default=0.3]\n",
    "2. min_child_weight [default=1]\n",
    "3. max_depth [default=6]\n",
    "4. gamma [default=0]\n",
    "5. max_leaf_nodes\n",
    "6. max_delta_step [default=0]\n",
    "7. subsample [default=1]\n",
    "8. colsample_bytree [default=1]\n",
    "9. colsample_bylevel [default=1]\n",
    "10. alpha [default=0]\n",
    "11. scale_pos_weight [default=1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Fix learning rate and number of estimators for tuning tree-based parameters\n",
    "In order to decide on boosting parameters, we need to set some initial values of other parameters. Lets take the following values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. max_depth = 5 :\n",
    " This should be between 3-10. I’ve started with 5 but you can choose a different number as well. 4-6 can be good starting points.\n",
    "2. min_child_weight = 1 :\n",
    " A smaller value is chosen because it is a highly imbalanced class problem and leaf nodes can have smaller size groups.\n",
    "3. gamma = 0 : \n",
    " A smaller value like 0.1-0.2 can also be chosen for starting. This will anyways be tuned later.\n",
    "4. subsample, colsample_bytree = 0.8 :\n",
    " This is a commonly used used start value. Typical values range between 0.5-0.9.\n",
    "5. scale_pos_weight = 1:\n",
    "  Because of high class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.93      0.94      0.94       454\n",
      "       real       0.94      0.94      0.94       497\n",
      "\n",
      "avg / total       0.94      0.94      0.94       951\n",
      "\n",
      "0.9390115667718192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "xgb1.fit(x_train, y_train)\n",
    "y_vpred = xgb1.predict(x_validation)\n",
    "\n",
    "target_names = ['fake', 'real']\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_validation, y_vpred, target_names=target_names))\n",
    "print(xgb1.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Tune max_depth and min_child_weight\n",
    "We tune these first as they will have the highest impact on model outcome. To start with, let’s set wider ranges and then we will perform another iteration for smaller ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=2, missing=None, n_estimators=140,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'max_depth': [4, 5, 6], 'min_child_weight': [4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96826, std: 0.01209, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: 0.96797, std: 0.01102, params: {'max_depth': 4, 'min_child_weight': 5},\n",
       "  mean: 0.96829, std: 0.01161, params: {'max_depth': 4, 'min_child_weight': 6},\n",
       "  mean: 0.96799, std: 0.01151, params: {'max_depth': 5, 'min_child_weight': 4},\n",
       "  mean: 0.96883, std: 0.01286, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.96808, std: 0.01258, params: {'max_depth': 5, 'min_child_weight': 6},\n",
       "  mean: 0.96836, std: 0.01062, params: {'max_depth': 6, 'min_child_weight': 4},\n",
       "  mean: 0.96793, std: 0.01215, params: {'max_depth': 6, 'min_child_weight': 5},\n",
       "  mean: 0.96882, std: 0.01281, params: {'max_depth': 6, 'min_child_weight': 6}],\n",
       " {'max_depth': 5, 'min_child_weight': 5},\n",
       " 0.9688293188293187)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have run 12 combinations with wider intervals between values. The ideal values are 5 for max_depth and 5 for min_child_weight. Lets go one step deeper and look for optimum values. We’ll search for values 1 above and below the optimum values because we took an interval of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=2, missing=None, n_estimators=140,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'max_depth': [4, 5, 6], 'min_child_weight': [4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    "    'max_depth':[4,5,6],\n",
    "    'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96826, std: 0.01209, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: 0.96797, std: 0.01102, params: {'max_depth': 4, 'min_child_weight': 5},\n",
       "  mean: 0.96829, std: 0.01161, params: {'max_depth': 4, 'min_child_weight': 6},\n",
       "  mean: 0.96799, std: 0.01151, params: {'max_depth': 5, 'min_child_weight': 4},\n",
       "  mean: 0.96883, std: 0.01286, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.96808, std: 0.01258, params: {'max_depth': 5, 'min_child_weight': 6},\n",
       "  mean: 0.96836, std: 0.01062, params: {'max_depth': 6, 'min_child_weight': 4},\n",
       "  mean: 0.96793, std: 0.01215, params: {'max_depth': 6, 'min_child_weight': 5},\n",
       "  mean: 0.96882, std: 0.01281, params: {'max_depth': 6, 'min_child_weight': 6}],\n",
       " {'max_depth': 5, 'min_child_weight': 5},\n",
       " 0.9688293188293187)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Tune gamma\n",
    "Now lets tune gamma value using the parameters already tuned above. Gamma can take various values but I’ll check for 5 values here. You can go into more precise values as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=5, missing=None, n_estimators=140,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96883, std: 0.01286, params: {'gamma': 0.0},\n",
       "  mean: 0.96737, std: 0.01144, params: {'gamma': 0.1},\n",
       "  mean: 0.96635, std: 0.01185, params: {'gamma': 0.2},\n",
       "  mean: 0.96759, std: 0.01261, params: {'gamma': 0.3},\n",
       "  mean: 0.96710, std: 0.01297, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.0},\n",
       " 0.9688293188293187)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Tune subsample and colsample_bytree\n",
    "The next step would be try different subsample and colsample_bytree values. Lets do this in 2 stages as well and take values 0.6,0.7,0.8,0.9 for both to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
       "       n_estimators=140, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=5, gamma=0.0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96891, std: 0.01188, params: {'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "  mean: 0.96693, std: 0.01393, params: {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "  mean: 0.96870, std: 0.01024, params: {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "  mean: 0.96762, std: 0.01178, params: {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "  mean: 0.96830, std: 0.01058, params: {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "  mean: 0.96836, std: 0.01502, params: {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "  mean: 0.96801, std: 0.01179, params: {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "  mean: 0.96622, std: 0.00968, params: {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "  mean: 0.96906, std: 0.00866, params: {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "  mean: 0.96824, std: 0.01265, params: {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "  mean: 0.96883, std: 0.01286, params: {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "  mean: 0.96728, std: 0.01017, params: {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "  mean: 0.96655, std: 0.01342, params: {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "  mean: 0.96771, std: 0.01127, params: {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "  mean: 0.96657, std: 0.01134, params: {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "  mean: 0.96662, std: 0.01274, params: {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       " 0.9690576337243005)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
       "       n_estimators=140, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.6),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'reg_alpha': [1e-05, 0.01, 0.1, 1, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=5, gamma=0.0, subsample=0.6, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96906, std: 0.00866, params: {'reg_alpha': 1e-05},\n",
       "  mean: 0.96797, std: 0.01068, params: {'reg_alpha': 0.01},\n",
       "  mean: 0.96869, std: 0.01151, params: {'reg_alpha': 0.1},\n",
       "  mean: 0.96819, std: 0.01018, params: {'reg_alpha': 1},\n",
       "  mean: 0.50000, std: 0.00000, params: {'reg_alpha': 100}],\n",
       " {'reg_alpha': 1e-05},\n",
       " 0.9690576337243005)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
       "       n_estimators=140, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.6),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'reg_alpha': [1e-05, 5e-05, 0.0001, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    "    'reg_alpha':[0.00001, 0.00005, 0.0001, 0.0005]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=5, gamma=0.0, subsample=0.6, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.96906, std: 0.00866, params: {'reg_alpha': 1e-05},\n",
       "  mean: 0.96906, std: 0.00866, params: {'reg_alpha': 5e-05},\n",
       "  mean: 0.96906, std: 0.00866, params: {'reg_alpha': 0.0001},\n",
       "  mean: 0.96919, std: 0.00871, params: {'reg_alpha': 0.0005}],\n",
       " {'reg_alpha': 0.0005},\n",
       " 0.9691895018561685)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.94      0.94      0.94       454\n",
      "       real       0.94      0.95      0.94       497\n",
      "\n",
      "avg / total       0.94      0.94      0.94       951\n",
      "\n",
      "0.9421661409043113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.0,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.0005,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "xgb2.fit(x_train, y_train)\n",
    "y_vpred = xgb2.predict(x_validation)\n",
    "\n",
    "target_names = ['fake', 'real']\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_validation, y_vpred, target_names=target_names))\n",
    "print(xgb2.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Reducing Learning Rate\n",
    "Lastly, we should lower the learning rate and add more trees. Lets use the cv function of XGBoost to do the job again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.94      0.94      0.94       454\n",
      "       real       0.95      0.95      0.95       497\n",
      "\n",
      "avg / total       0.94      0.94      0.94       951\n",
      "\n",
      "0.9442691903259727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=5000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.0,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.0005,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "xgb3.fit(x_train, y_train)\n",
    "y_vpred = xgb3.predict(x_validation)\n",
    "\n",
    "target_names = ['fake', 'real']\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_validation, y_vpred, target_names=target_names))\n",
    "print(xgb3.score(x_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conclusion for this part\n",
    "after we reduce the leanring rate and accordingly increased the tree, the accuracy only impove little but longer time cost in the xgb3, so we don't think that xgb3 is better than xgb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake       0.95      0.94      0.94       492\n",
      "       real       0.94      0.94      0.94       459\n",
      "\n",
      "avg / total       0.94      0.94      0.94       951\n",
      "\n",
      "0.9411146161934806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "D:\\program files(X86)\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.0,\n",
    "        subsample=0.6,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.0005,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "xgb2.fit(x_train, y_train)\n",
    "y_pred = xgb2.predict(x_test)\n",
    "\n",
    "target_names = ['fake', 'real']\n",
    "print(\"XGBoost:\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(xgb2.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
