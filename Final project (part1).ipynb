{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project (part 1)\n",
    "\n",
    "Team leader: Zhaoliang Zheng\n",
    "\n",
    "Team member: Anqi Shen, Enbo Yu\n",
    "\n",
    "#### step1: data preprocessing\n",
    "#### step2: data processing\n",
    "#### step3: feature extraction and vectorization\n",
    "#### step4: train, test validation set split\n",
    "#### step5: building classifiers\n",
    "#### step6: hypertuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzl\\data\\final project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ROOTDIR = os.path.abspath(os.path.dirname('__file__'))\n",
    "print(ROOTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[ 1.1533764e-02  4.2144405e-03  1.9692603e-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[ 0.11267698  0.02518966 -0.00212591  0.021095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[ 0.04253004  0.04300297  0.01848392  0.048672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>[ 0.10801624  0.11583211  0.02874823  0.061732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[ 1.69016439e-02  7.13498285e-03 -7.81233795e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE   \n",
       "4  It's primary day in New York and front-runners...  REAL   \n",
       "\n",
       "                                       title_vectors  \n",
       "0  [ 1.1533764e-02  4.2144405e-03  1.9692603e-02 ...  \n",
       "1  [ 0.11267698  0.02518966 -0.00212591  0.021095...  \n",
       "2  [ 0.04253004  0.04300297  0.01848392  0.048672...  \n",
       "3  [ 0.10801624  0.11583211  0.02874823  0.061732...  \n",
       "4  [ 1.69016439e-02  7.13498285e-03 -7.81233795e-...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Load dataset and check it\n",
    "df = pd.read_csv(os.path.join(ROOTDIR, 'fake_or_real_news.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a binarize function and binrize the label\n",
    "def binarize(word):\n",
    "    if word== 'REAL':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "df.label= df.label.apply(binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in this step, I'm gonna drop the first column which is meaningless here\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 1.1533764e-02  4.2144405e-03  1.9692603e-02 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.11267698  0.02518966 -0.00212591  0.021095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.04253004  0.04300297  0.01848392  0.048672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.10801624  0.11583211  0.02874823  0.061732...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 1.69016439e-02  7.13498285e-03 -7.81233795e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       You Can Smell Hillary’s Fear   \n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        Kerry to go to Paris in gesture of sympathy   \n",
       "3  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      1   \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      1   \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      0   \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      1   \n",
       "4  It's primary day in New York and front-runners...      0   \n",
       "\n",
       "                                       title_vectors  \n",
       "0  [ 1.1533764e-02  4.2144405e-03  1.9692603e-02 ...  \n",
       "1  [ 0.11267698  0.02518966 -0.00212591  0.021095...  \n",
       "2  [ 0.04253004  0.04300297  0.01848392  0.048672...  \n",
       "3  [ 0.10801624  0.11583211  0.02874823  0.061732...  \n",
       "4  [ 1.69016439e-02  7.13498285e-03 -7.81233795e-...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: DATA PROCESSING:TOKENIZE & CLEAN THE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from gensim import models\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load raw title and text dataset into different varibles\n",
    "texts = df.text.values\n",
    "titles = df.title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simply tokenize the text and title\n",
    "tokenized_text = [nltk.word_tokenize(text) for text in texts]\n",
    "tokenized_title = [nltk.word_tokenize(title) for title in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the high frequency words in top 20\n",
    "\n",
    "we find out that there are lots of stop words, punctuations and useless mark in the tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.        the  freq:    2111\n",
      " 2.         to  freq:    1714\n",
      " 3.          :  freq:    1618\n",
      " 4.          ,  freq:    1409\n",
      " 5.          ’  freq:    1380\n",
      " 6.         in  freq:    1161\n",
      " 7.         of  freq:    1091\n",
      " 8.      trump  freq:    1079\n",
      " 9.        for  freq:     799\n",
      "10.         on  freq:     764\n",
      "11.          s  freq:     741\n",
      "12.          a  freq:     736\n",
      "13.    clinton  freq:     709\n",
      "14.         is  freq:     700\n",
      "15.        and  freq:     693\n",
      "16.    hillary  freq:     580\n",
      "17.         's  freq:     566\n",
      "18.          ?  freq:     554\n",
      "19.      obama  freq:     375\n",
      "20.          '  freq:     373\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token_counter = Counter(token.lower() for sentence in tokenized_title for token in sentence)\n",
    "top20 = token_counter.most_common()[:20]\n",
    "for i, t in enumerate(top20):\n",
    "    print('{:>2}.{:>11}  freq: {:>7}'.format(i+1, t[0], t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define a clean_advance function to clean the text and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "def clean_advance(tokenized_list, sw):\n",
    "    new_list = []\n",
    "    for doc in tokenized_list:\n",
    "        new_list.append([token.lower() for token in doc if token.lower() not in sw\n",
    "                        and token.lower() != \"“\" and token.lower() != \"”\"\n",
    "                        and token.lower() != \"‘\" and token.lower() != \"’\"\n",
    "                        and token.lower() != \"``\" and token.lower() != \"''\"\n",
    "                        and token.lower() != \"—\"  and token.lower() != \"–\"\n",
    "                        and token.lower() !=\",\" and token.lower() != \".\"\n",
    "                        and token.lower() != \":\" and token.lower() != \"?\"\n",
    "                        and token.lower() != \"(\" and token.lower() != \")\"\n",
    "                        and token.lower() != \"'s\" and token.lower() != \"n't\"\n",
    "                        and token.lower() != \"'d\" and token.lower() != \"'ve\"\n",
    "                        and token.lower() != \"!\" and token.lower() != \"'\"\n",
    "                        and token.lower() != \"&\" and token.lower() != \"*\"\n",
    "                        and token.lower() != \"...\" and token.lower() != \"…\" \n",
    "                        and token.lower() != \"#\" and token.lower() != \"-\"\n",
    "                        and token.lower() != \"[\" and token.lower() != \"]\" \n",
    "                        and token.lower() != \"%\" and token.lower() !=\"|\" \n",
    "                        and token.lower() != \";\" ])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuations and stopwords,lower-case and other useless mark from tokenized title and text\n",
    "cleaned_title = clean_advance(tokenized_title, sw)\n",
    "cleaned_text = clean_advance(tokenized_text, sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.      trump  freq:   21906\n",
      " 2.       said  freq:   21162\n",
      " 3.    clinton  freq:   17237\n",
      " 4.      would  freq:   12928\n",
      " 5.     people  freq:   11598\n",
      " 6.        one  freq:   11295\n",
      " 7.        new  freq:    9263\n",
      " 8.      state  freq:    8744\n",
      " 9.  president  freq:    8509\n",
      "10.       also  freq:    8206\n",
      "11.      obama  freq:    8121\n",
      "12.   campaign  freq:    7642\n",
      "13.         us  freq:    7511\n",
      "14.    hillary  freq:    7127\n",
      "15.       like  freq:    7038\n",
      "16.      could  freq:    6705\n",
      "17.       time  freq:    6432\n",
      "18.       even  freq:    6424\n",
      "19.     states  freq:    6142\n",
      "20.       many  freq:    5847\n"
     ]
    }
   ],
   "source": [
    "token_counter = Counter(token.lower() for sentence in cleaned_text for token in sentence)\n",
    "top20 = token_counter.most_common()[:20]\n",
    "for i, t in enumerate(top20):\n",
    "    print('{:>2}.{:>11}  freq: {:>7}'.format(i+1, t[0], t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1：Extend title with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "c_extend=copy.deepcopy(cleaned_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(texts.shape[0]):\n",
    "   c_extend[i].extend(cleaned_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "clean_extend=pd.DataFrame(data=c_extend)\n",
    "clean_extend.to_csv('clean_extend.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this way we only combine title and text and put into a list\n",
    "\n",
    "essentially we just parallelly load more information into our text\n",
    "\n",
    "then we do verterization and feature engineering to the clean_extend dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2：Extend title with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cleantitle=pd.DataFrame(data=cleaned_title)\n",
    "cleantext=pd.DataFrame(data=cleaned_text)\n",
    "cleantitle.to_csv('clean_title.csv',index=False,header=False)\n",
    "cleantext.to_csv('clean_text.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can just seperatly output our cleaned title and text \n",
    "\n",
    "then seperatly do verterization and feature engineering to these two datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smell', 'hillary', 'fear']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_title[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
